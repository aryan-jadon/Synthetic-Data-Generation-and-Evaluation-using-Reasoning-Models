{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ddae552-0694-4727-a58f-d3c5bca83360",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c141c6c-3a71-45b2-82bb-728c4d1c8bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryanjadon/miniconda3/envs/papers_2025/lib/python3.11/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import os\n",
    "import pdb\n",
    "import re\n",
    "import ast\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from importlib import resources\n",
    "from IPython.display import display, clear_output\n",
    "from chunking_evaluation.utils import rigorous_document_search\n",
    "from chunking_evaluation.evaluation_framework.base_evaluation import BaseEvaluation\n",
    "\n",
    "class SyntheticEvaluation(BaseEvaluation):\n",
    "    def __init__(self, corpora_paths: List[str], queries_csv_path: str, chroma_db_path: str = None,\n",
    "                 openai_api_key=None):\n",
    "        super().__init__(questions_csv_path=queries_csv_path, chroma_db_path=chroma_db_path)\n",
    "        self.corpora_paths = corpora_paths\n",
    "        self.questions_csv_path = queries_csv_path\n",
    "        self.client = OpenAI(base_url=\"Your-URL-HERE\", api_key=\"XXXX-Your-API-Key-Here-XXX\")\n",
    "        self.synth_questions_df = None\n",
    "\n",
    "        with resources.as_file(resources.files('chunking_evaluation.evaluation_framework') / 'prompts') as prompt_path:\n",
    "            with open(os.path.join(prompt_path, 'question_maker_system.txt'), 'r') as f:\n",
    "                self.question_maker_system_prompt = f.read()\n",
    "\n",
    "            with open(os.path.join(prompt_path, 'question_maker_approx_system.txt'), 'r') as f:\n",
    "                self.question_maker_approx_system_prompt = f.read()\n",
    "\n",
    "            with open(os.path.join(prompt_path, 'question_maker_user.txt'), 'r') as f:\n",
    "                self.question_maker_user_prompt = f.read()\n",
    "\n",
    "            with open(os.path.join(prompt_path, 'question_maker_approx_user.txt'), 'r') as f:\n",
    "                self.question_maker_approx_user_prompt = f.read()\n",
    "\n",
    "    def _save_questions_df(self):\n",
    "        self.synth_questions_df.to_csv(self.questions_csv_path, index=False)\n",
    "\n",
    "    def _tag_text(self, text):\n",
    "        chunk_length = 100\n",
    "        chunks = []\n",
    "        tag_indexes = [0]\n",
    "        start = 0\n",
    "        while start < len(text):\n",
    "            end = start + chunk_length\n",
    "            chunk = text[start:end]\n",
    "            if end < len(text):\n",
    "                # Find the last space within the chunk to avoid splitting a word\n",
    "                space_index = chunk.rfind(' ')\n",
    "                if space_index != -1:\n",
    "                    end = start + space_index + 1  # Include the space in the chunk\n",
    "                    chunk = text[start:end]\n",
    "            chunks.append(chunk)\n",
    "            tag_indexes.append(end)\n",
    "            start = end  # Move start to end to continue splitting\n",
    "\n",
    "        tagged_text = \"\"\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            tagged_text += f\"<start_chunk_{i}>\" + chunk + f\"<end_chunk_{i}>\"\n",
    "\n",
    "        return tagged_text, tag_indexes\n",
    "\n",
    "    def convert_text_to_json(self,text: str):\n",
    "        \"\"\"\n",
    "        Removes the text between <think> and </think> tags and converts\n",
    "        the remaining text (assumed to be a Python dictionary literal)\n",
    "        into a JSON string.\n",
    "    \n",
    "        Args:\n",
    "            text (str): The original text containing a <think>...</think> block\n",
    "                        and the dictionary to convert.\n",
    "    \n",
    "        Returns:\n",
    "            str: A JSON-formatted string representing the dictionary.\n",
    "        \"\"\"\n",
    "        # Remove everything between <think> and </think> (including the tags)\n",
    "        cleaned_text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)\n",
    "    \n",
    "        # Strip any leading/trailing whitespace\n",
    "        cleaned_text = cleaned_text.strip()\n",
    "    \n",
    "        # Parse the remaining text as a Python literal.\n",
    "        # (Using ast.literal_eval since the text is written as a Python dictionary.)\n",
    "        try:\n",
    "            data = ast.literal_eval(cleaned_text)\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"Failed to parse the remaining text as a dictionary: \" + str(e))\n",
    "    \n",
    "        # Convert the Python dictionary to a JSON-formatted string\n",
    "        json_response = json.dumps(data, indent=2)\n",
    "        \n",
    "        return json_response\n",
    "\n",
    "    def _extract_question_and_approx_references(self, corpus, document_length=4000, prev_questions=[]):\n",
    "        \n",
    "        if len(corpus) > document_length:\n",
    "            start_index = random.randint(0, len(corpus) - document_length)\n",
    "            document = corpus[start_index: start_index + document_length]\n",
    "        else:\n",
    "            start_index = 0\n",
    "            document = corpus\n",
    "\n",
    "        if prev_questions is not None:\n",
    "            if len(prev_questions) > 20:\n",
    "                questions_sample = random.sample(prev_questions, 20)\n",
    "                prev_questions_str = '\\n'.join(questions_sample)\n",
    "            else:\n",
    "                prev_questions_str = '\\n'.join(prev_questions)\n",
    "        else:\n",
    "            prev_questions_str = \"\"\n",
    "\n",
    "        tagged_text, tag_indexes = self._tag_text(document)\n",
    "\n",
    "        completion = self.client.chat.completions.create(\n",
    "            model=\"deepseek-ai/DeepSeek-R1-Distill-Llama-70B\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.question_maker_approx_system_prompt},\n",
    "                {\"role\": \"user\",\n",
    "                 \"content\": self.question_maker_approx_user_prompt.replace(\"{document}\", tagged_text).replace(\n",
    "                     \"{prev_questions_str}\", prev_questions_str)}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        response = completion.choices[0].message.content\n",
    "        json_response = json.loads(self.convert_text_to_json(response))\n",
    "        \n",
    "        print(json_response)\n",
    "        \n",
    "        try:\n",
    "            text_references = json_response['references']\n",
    "        except KeyError:\n",
    "            raise ValueError(\"The response does not contain a 'references' field.\")\n",
    "\n",
    "        try:\n",
    "            question = json_response['question']\n",
    "        except KeyError:\n",
    "            raise ValueError(\"The response does not contain a 'question' field.\")\n",
    "\n",
    "        \n",
    "        references = []\n",
    "    \n",
    "        for reference in text_references:\n",
    "            try:\n",
    "                reference_keys = list(reference.keys())\n",
    "    \n",
    "                if len(reference_keys) != 3:\n",
    "                    raise ValueError(\n",
    "                        f\"Each reference must have exactly 3 keys: 'content', 'start_chunk', and 'end_chunk'. Got keys: {reference_keys}\")\n",
    "    \n",
    "                if 'start_chunk' not in reference_keys or 'end_chunk' not in reference_keys:\n",
    "                    raise ValueError(\"Each reference must contain 'start_chunk' and 'end_chunk' keys.\")\n",
    "    \n",
    "                if 'end_chunk' not in reference_keys:\n",
    "                    reference_keys.remove('content')\n",
    "                    reference_keys.remove('start_chunk')\n",
    "                    end_chunk_key = reference_keys[0]\n",
    "                    end_index = start_index + tag_indexes[reference[end_chunk_key] + 1]\n",
    "                else:\n",
    "                    end_index = start_index + tag_indexes[reference['end_chunk'] + 1]\n",
    "    \n",
    "                start_index = start_index + tag_indexes[reference['start_chunk']]\n",
    "                references.append((corpus[start_index:end_index], start_index, end_index))\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                \n",
    "        return question, references\n",
    "\n",
    "    def _extract_question_and_references(self, corpus, document_length=4000, prev_questions=[]):\n",
    "        if len(corpus) > document_length:\n",
    "            start_index = random.randint(0, len(corpus) - document_length)\n",
    "            document = corpus[start_index: start_index + document_length]\n",
    "        else:\n",
    "            document = corpus\n",
    "\n",
    "        if prev_questions is not None:\n",
    "            if len(prev_questions) > 20:\n",
    "                questions_sample = random.sample(prev_questions, 20)\n",
    "                prev_questions_str = '\\n'.join(questions_sample)\n",
    "            else:\n",
    "                prev_questions_str = '\\n'.join(prev_questions)\n",
    "        else:\n",
    "            prev_questions_str = \"\"\n",
    "\n",
    "        completion = self.client.chat.completions.create(\n",
    "            model=\"deepseek-ai/DeepSeek-R1-Distill-Llama-70B\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.question_maker_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": self.question_maker_user_prompt.replace(\"{document}\", document).replace(\n",
    "                    \"{prev_questions_str}\", prev_questions_str)}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        response = completion.choices[0].message\n",
    "        json_response = json.loads(response.json())\n",
    "        \n",
    "        input_str = json_response['content']\n",
    "        # new_string = self.remove_think_tags(input_str)\n",
    "        new_string = input_str.replace(\"```json\", \"```\")\n",
    "        cleaned_string = new_string.strip().strip('```').strip()\n",
    "            \n",
    "        parsed_dict = json.loads(input_str)\n",
    "        print(parsed_dict)\n",
    "        \n",
    "        json_response = parsed_dict\n",
    "\n",
    "\n",
    "        try:\n",
    "            text_references = json_response['references']\n",
    "        except KeyError:\n",
    "            raise ValueError(\"The response does not contain a 'references' field.\")\n",
    "\n",
    "        try:\n",
    "            question = json_response['question']\n",
    "        except KeyError:\n",
    "            raise ValueError(\"The response does not contain a 'question' field.\")\n",
    "\n",
    "        references = []\n",
    "        for reference in text_references:\n",
    "            if not isinstance(reference, str):\n",
    "                raise ValueError(f\"Expected reference to be of type str, but got {type(reference).__name__}\")\n",
    "            target = rigorous_document_search(corpus, reference)\n",
    "            if target is not None:\n",
    "                reference, start_index, end_index = target\n",
    "                references.append((reference, start_index, end_index))\n",
    "            else:\n",
    "                raise ValueError(f\"No match found in the document for the given reference.\\nReference: {reference}\")\n",
    "\n",
    "        return question, references\n",
    "\n",
    "    def _generate_corpus_questions(self, corpus_id, approx=False, n=5):\n",
    "        with open(corpus_id, 'r') as file:\n",
    "            corpus = file.read()\n",
    "\n",
    "        i = 0\n",
    "        while i < n:\n",
    "            while True:\n",
    "                try:\n",
    "                    print(f\"Trying Query {i}\")\n",
    "                    questions_list = self.synth_questions_df[self.synth_questions_df['corpus_id'] == corpus_id][\n",
    "                        'question'].tolist()\n",
    "                    if approx:\n",
    "                        question, references = self._extract_question_and_approx_references(corpus, 4000,\n",
    "                                                                                            questions_list)\n",
    "                    else:\n",
    "                        question, references = self._extract_question_and_references(corpus, 4000, questions_list)\n",
    "                    if len(references) > 5:\n",
    "                        raise ValueError(\"The number of references exceeds 5.\")\n",
    "\n",
    "                    references = [{'content': ref[0], 'start_index': ref[1], 'end_index': ref[2]} for ref in references]\n",
    "                    new_question = {\n",
    "                        'question': question,\n",
    "                        'references': json.dumps(references),\n",
    "                        'corpus_id': corpus_id\n",
    "                    }\n",
    "\n",
    "                    new_df = pd.DataFrame([new_question])\n",
    "                    self.synth_questions_df = pd.concat([self.synth_questions_df, new_df], ignore_index=True)\n",
    "                    self._save_questions_df()\n",
    "\n",
    "                    break\n",
    "                except (ValueError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error occurred: {e}\")\n",
    "                    continue\n",
    "            i += 1\n",
    "\n",
    "    def _get_synth_questions_df(self):\n",
    "        if os.path.exists(self.questions_csv_path):\n",
    "            synth_questions_df = pd.read_csv(self.questions_csv_path)\n",
    "        else:\n",
    "            synth_questions_df = pd.DataFrame(columns=['question', 'references', 'corpus_id'])\n",
    "        return synth_questions_df\n",
    "\n",
    "    def generate_queries_and_excerpts(self, approximate_excerpts=False, num_rounds=-1, queries_per_corpus=5):\n",
    "        self.synth_questions_df = self._get_synth_questions_df()\n",
    "\n",
    "        rounds = 0\n",
    "        while num_rounds == -1 or rounds < num_rounds:\n",
    "            for corpus_id in self.corpora_paths:\n",
    "                self._generate_corpus_questions(corpus_id, approx=approximate_excerpts, n=queries_per_corpus)\n",
    "            rounds += 1\n",
    "\n",
    "    def _get_sim(self, target, references):\n",
    "        response = self.client.embeddings.create(\n",
    "            input=[target] + references,\n",
    "            model=\"text-embedding-bge-m3\"\n",
    "        )\n",
    "        nparray1 = np.array(response.data[0].embedding)\n",
    "\n",
    "        full_sim = []\n",
    "        for i in range(1, len(response.data)):\n",
    "            nparray2 = np.array(response.data[i].embedding)\n",
    "            cosine_similarity = np.dot(nparray1, nparray2) / (np.linalg.norm(nparray1) * np.linalg.norm(nparray2))\n",
    "            full_sim.append(cosine_similarity)\n",
    "\n",
    "        return full_sim\n",
    "\n",
    "    def _corpus_filter_poor_highlights(self, corpus_id, synth_questions_df, threshold):\n",
    "        corpus_questions_df = synth_questions_df[synth_questions_df['corpus_id'] == corpus_id]\n",
    "\n",
    "        def edit_row(row):\n",
    "            question = row['question']\n",
    "            references = [ref['content'] for ref in row['references']]\n",
    "            similarity_scores = self._get_sim(question, references)\n",
    "            worst_ref_score = min(similarity_scores)\n",
    "            row['worst_ref_score'] = worst_ref_score\n",
    "            return row\n",
    "\n",
    "        # Apply the function to each row\n",
    "        corpus_questions_df = corpus_questions_df.apply(edit_row, axis=1)\n",
    "\n",
    "        count_before = len(corpus_questions_df)\n",
    "\n",
    "        corpus_questions_df = corpus_questions_df[corpus_questions_df['worst_ref_score'] >= threshold]\n",
    "        corpus_questions_df = corpus_questions_df.drop(columns=['worst_ref_score'])\n",
    "\n",
    "        count_after = len(corpus_questions_df)\n",
    "\n",
    "        print(f\"Corpus: {corpus_id} - Removed {count_before - count_after} .\")\n",
    "\n",
    "        corpus_questions_df['references'] = corpus_questions_df['references'].apply(json.dumps)\n",
    "\n",
    "        full_questions_df = pd.read_csv(self.questions_csv_path)\n",
    "        full_questions_df = full_questions_df[full_questions_df['corpus_id'] != corpus_id]\n",
    "\n",
    "        full_questions_df = pd.concat([full_questions_df, corpus_questions_df], ignore_index=True)\n",
    "        # Drop the columns 'fixed', 'worst_ref_score' and 'diff_score' if they exist\n",
    "        for col in ['fixed', 'worst_ref_score', 'diff_score']:\n",
    "            if col in full_questions_df.columns:\n",
    "                full_questions_df = full_questions_df.drop(columns=col)\n",
    "\n",
    "        full_questions_df.to_csv(self.questions_csv_path, index=False)\n",
    "\n",
    "    def filter_poor_excerpts(self, threshold=0.36, corpora_subset=[]):\n",
    "        if os.path.exists(self.questions_csv_path):\n",
    "            synth_questions_df = pd.read_csv(self.questions_csv_path)\n",
    "            if len(synth_questions_df) > 0:\n",
    "                synth_questions_df['references'] = synth_questions_df['references'].apply(json.loads)\n",
    "                corpus_list = synth_questions_df['corpus_id'].unique().tolist()\n",
    "                if corpora_subset:\n",
    "                    corpus_list = [c for c in corpus_list if c in corpora_subset]\n",
    "                for corpus_id in corpus_list:\n",
    "                    self._corpus_filter_poor_highlights(corpus_id, synth_questions_df, threshold)\n",
    "\n",
    "    def _corpus_filter_duplicates(self, corpus_id, synth_questions_df, threshold):\n",
    "        corpus_questions_df = synth_questions_df[synth_questions_df['corpus_id'] == corpus_id].copy()\n",
    "\n",
    "        count_before = len(corpus_questions_df)\n",
    "\n",
    "        corpus_questions_df.drop_duplicates(subset='question', keep='first', inplace=True)\n",
    "\n",
    "        questions = corpus_questions_df['question'].tolist()\n",
    "\n",
    "        response = self.client.embeddings.create(\n",
    "            input=questions,\n",
    "            model=\"text-embedding-bge-m3\"\n",
    "        )\n",
    "\n",
    "        embeddings_matrix = np.array([data.embedding for data in response.data])\n",
    "\n",
    "        dot_product_matrix = np.dot(embeddings_matrix, embeddings_matrix.T)\n",
    "\n",
    "        # Create a list of tuples containing the index pairs and their similarity\n",
    "        similarity_pairs = [(i, j, dot_product_matrix[i][j]) for i in range(len(dot_product_matrix)) for j in\n",
    "                            range(i + 1, len(dot_product_matrix))]\n",
    "\n",
    "        # Sort the list of tuples based on the similarity in descending order\n",
    "        similarity_pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "        similarity_scores = np.array([x[2] for x in similarity_pairs])\n",
    "\n",
    "        most_similars = (dot_product_matrix - np.eye(dot_product_matrix.shape[0])).max(axis=1)\n",
    "\n",
    "        def filter_vectors(sim_matrix, threshold):\n",
    "            n = sim_matrix.shape[0]  # Number of vectors\n",
    "            remaining = np.ones(n, dtype=bool)  # Initialize all vectors as remaining\n",
    "\n",
    "            for i in range(n):\n",
    "                if remaining[i] == 1:  # Only check for vectors that are still remaining\n",
    "                    for j in range(i + 1, n):\n",
    "                        if remaining[j] == 1 and sim_matrix[i, j] > threshold:\n",
    "                            remaining[j] = 0  # Remove vector j because it's too similar to vector i\n",
    "\n",
    "            return remaining\n",
    "\n",
    "        rows_to_keep = filter_vectors(dot_product_matrix, threshold)\n",
    "\n",
    "        corpus_questions_df = corpus_questions_df[rows_to_keep]\n",
    "\n",
    "        count_after = len(corpus_questions_df)\n",
    "\n",
    "        print(f\"Corpus: {corpus_id} - Removed {count_before - count_after} .\")\n",
    "\n",
    "        corpus_questions_df['references'] = corpus_questions_df['references'].apply(json.dumps)\n",
    "\n",
    "        full_questions_df = pd.read_csv(self.questions_csv_path)\n",
    "        full_questions_df = full_questions_df[full_questions_df['corpus_id'] != corpus_id]\n",
    "\n",
    "        full_questions_df = pd.concat([full_questions_df, corpus_questions_df], ignore_index=True)\n",
    "        # Drop the columns 'fixed', 'worst_ref_score' and 'diff_score' if they exist\n",
    "        for col in ['fixed', 'worst_ref_score', 'diff_score']:\n",
    "            if col in full_questions_df.columns:\n",
    "                full_questions_df = full_questions_df.drop(columns=col)\n",
    "\n",
    "        full_questions_df.to_csv(self.questions_csv_path, index=False)\n",
    "\n",
    "    def filter_duplicates(self, threshold=0.78, corpora_subset=[]):\n",
    "        if os.path.exists(self.questions_csv_path):\n",
    "            synth_questions_df = pd.read_csv(self.questions_csv_path)\n",
    "            if len(synth_questions_df) > 0:\n",
    "                synth_questions_df['references'] = synth_questions_df['references'].apply(json.loads)\n",
    "                corpus_list = synth_questions_df['corpus_id'].unique().tolist()\n",
    "                if corpora_subset:\n",
    "                    corpus_list = [c for c in corpus_list if c in corpora_subset]\n",
    "                for corpus_id in corpus_list:\n",
    "                    self._corpus_filter_duplicates(corpus_id, synth_questions_df, threshold)\n",
    "\n",
    "    def question_ref_filter(self):\n",
    "        self.synth_questions_df = self._get_synth_questions_df()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "778be8d8-fcb5-4aa7-85c1-34a034a8dc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying Query 0\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What supplementary NSA guidance is available for ensuring a secure network environment?', 'references': [{'content': 'Supplementary NSA guidance on ensuring a secure and defensible network environment is available at www.nsa.gov/cybersecurity-guidance. Of particular relevance are:', 'start_chunk': 13, 'end_chunk': 14}, {'content': 's Top Ten Cybersecurity Mitigation Strategies', 'start_chunk': 15, 'end_chunk': 15}, {'content': 'Defend Privileges and Accounts', 'start_chunk': 15, 'end_chunk': 15}, {'content': 'Continuously Hunt for Network Intrusions', 'start_chunk': 16, 'end_chunk': 16}, {'content': 'Segment Networks and Deploy Application-aware Defenses', 'start_chunk': 16, 'end_chunk': 16}]}\n",
      "Trying Query 1\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: unterminated string literal (detected at line 7) (<unknown>, line 7)\n",
      "Trying Query 1\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What are the key steps to mitigate the modification of test benches to reduce coverage or hide Trojan code in FPGA applications?', 'references': [{'content': 'Create and execute a documented test plan that identifies the various test reviews that will take place, analysis to be performed, type of testing to be performed, and the methods used to accomplish the test.', 'start_chunk': 10, 'end_chunk': 11}, {'content': 'Validate and verify test processes which include design/test team separation, peer reviews, and use of automated tools where applicable.', 'start_chunk': 12, 'end_chunk': 13}, {'content': 'Maintain test environment via configuration management as a critical system.', 'start_chunk': 14, 'end_chunk': 15}]}\n",
      "Trying Query 2\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 2\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 2\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 2\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What Execution techniques does an MCA employ to exploit a DevSecOps CI/CD cloud environment, and what mitigations are suggested by D3FEND?', 'references': [{'content': 'Execution consists of techniques that result in adversary-controlled code running on a blue space system. Techniques that run malicious code are often paired with techniques from any other tactics to achieve broader goals, such as exploring a network or stealing data. For Execution, an MCA may employ the following ATT&CK Tactic, Techniques/Sub-Techniques to exploit a DevSecOps CI/CD cloud environment:', 'start_chunk': 2, 'end_chunk': 5}, {'content': 'Container Administration Command [T1609] Command and Scripting Interpreter [T1059]', 'start_chunk': 6, 'end_chunk': 7}, {'content': 'D3FEND enumerates the following mitigations to counter these techniques: D3FEND Tactic Countermeasure Application Hardening Application Configuration Hardening [D3-ACH] Execution Isolation Executable Allow Listing [D3-EAL]', 'start_chunk': 8, 'end_chunk': 9}]}\n",
      "Trying Query 3\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: unterminated string literal (detected at line 5) (<unknown>, line 5)\n",
      "Trying Query 3\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'How do you create a text hexadecimal hash for an EFI binary using Windows PowerShell?', 'references': [{'content': 'To create a text hexadecimal hash:', 'start_chunk': 39, 'end_chunk': 40}, {'content': '$hashString = Get-AppLockerFileInformation helloworld.efi | select', 'start_chunk': 40, 'end_chunk': 41}]}\n",
      "Trying Query 4\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What key tasks are outlined in the FPGA configuration and testing process?', 'references': [{'content': 'Verify the SBCS configuration process', 'start_chunk': 2, 'end_chunk': 3}, {'content': 'Test non-volatile memory', 'start_chunk': 4, 'end_chunk': 5}, {'content': 'Document the steps', 'start_chunk': 6, 'end_chunk': 7}]}\n",
      "Trying Query 5\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 5\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 5\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 5\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 5\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What experiments were conducted in this study?', 'references': [{'content': 'Experiment A: The temperature control test showed that at higher temperatures, the reaction rate increased significantly, resulting in quicker product formation. However, at extremely high temperatures, the reaction yield decreased due to the degradation of reactants.', 'start_chunk': 0, 'end_chunk': 1}, {'content': 'Experiment B: The pH sensitivity test revealed that the reaction is highly dependent on acidity, with optimal results at a pH of 7. Deviating from this pH level in either direction led to a substantial drop in yield.', 'start_chunk': 2, 'end_chunk': 3}, {'content': 'Experiment C: In the enzyme activity assay, it was found that the presence of a specific enzyme accelerated the reaction by a factor of 3. The absence of the enzyme, however, led to a sluggish reaction with an extended completion time.', 'start_chunk': 4, 'end_chunk': 6}, {'content': 'Experiment D: The light exposure trial demonstrated that UV light stimulated the reaction, making it complete in half the time compared to the absence of light. Conversely, prolonged light exposure led to unwanted side reactions that contaminated the final product.', 'start_chunk': 7, 'end_chunk': 8}]}\n",
      "Trying Query 6\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What notable cyberattacks involved compromised credentials?', 'references': [{'content': 'In 2021, compromised credentials were used to attack and shut down the Colonial national gas pipeline in the U.S.', 'start_chunk': 15, 'end_chunk': 16}, {'content': 'In another 2021 cyberattack, an unknown attacker manipulated computer systems in a Florida water treatment plant to increase the concentration of sodium hydroxide in the water supply by a factor of 100.', 'start_chunk': 16, 'end_chunk': 17}, {'content': 'In 2022, another attack targeted a water treatment plant in South Staffordshire, U.K.', 'start_chunk': 18, 'end_chunk': 19}]}\n",
      "Trying Query 7\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What steps is NSA taking to encourage women in cybersecurity?', 'references': [{'content': 'Women comprise about 25 percent of the global cybersecurity workforce, according to a 2022 study by Cybersecurity Ventures. NSA is working with academic, industry, and government partners to encourage more women to pursue careers in cybersecurity.', 'start_chunk': 16, 'end_chunk': 18}, {'content': 'The Cybersecurity Collaboration Center (CCC) where the workforce is more than 50 percent women is leading the charge. For the past two years, the CCC has sponsored and participated in the Women in Cybersecurity (WiCyS) Conference.', 'start_chunk': 19, 'end_chunk': 20}, {'content': \"Participants have showcased NSA's cybersecurity mission and how diversity has helped NSA solve difficult problems. The CCC also is helping to recruit the next generation of cyber experts.\", 'start_chunk': 21, 'end_chunk': 22}, {'content': 'Hosted by CCC Chief Morgan Adamski, the short videos profile female cybersecurity leaders across the Intelligence Community.', 'start_chunk': 35, 'end_chunk': 36}]}\n",
      "Trying Query 8\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What folder structure does the actor create in the specified directory to store the ntds.dit database copy?', 'references': [{'content': 'an Active Directory folder that contains the ntds.dit and ntds.jfm files, and a registry folder that contains the SYSTEM and SECURITY hives.', 'start_chunk': 11, 'end_chunk': 12}, {'content': '<path specified in command>\\\\Active Directory\\\\ntds.dit', 'start_chunk': 13, 'end_chunk': 13}, {'content': '<path specified in command>\\\\Active Directory\\\\ntds.jfm', 'start_chunk': 14, 'end_chunk': 14}, {'content': '<path specified in command>\\\\registry\\\\SECURITY', 'start_chunk': 15, 'end_chunk': 15}, {'content': '<path specified in command>\\\\registry\\\\SYSTEM', 'start_chunk': 16, 'end_chunk': 16}]}\n",
      "Trying Query 9\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'How does Secure Boot prevent the execution of LoJax during the boot process?', 'references': [{'content': 'As another malware example, consider the case of a malicious UEFI module such as LoJax. LoJax is a malicious modification of the anti-theft solutions known as Computrace and LoJack. Secure Boot will not be able to validate LoJax against any DBX, DB, or KEK meaning that use of LoJax during boot should be prevented.', 'start_chunk': 20, 'end_chunk': 22}, {'content': 'Use Thorough Mode to force early-boot Secure Boot checks. Most servers ship with Thorough Mode enabled by default. Always check UEFI configuration upon receipt of a new system. Figure 3 displays how the anti-malware properties of Secure Boot would affect LoJax. Assuming the system boots in Thorough Mode, LoJax would be denied execution at boot time while all other UEFI services operate normally.', 'start_chunk': 24, 'end_chunk': 28}, {'content': 'Figure 3 - Secure Boot in Thorough Boot mode denying execution to Lojax malware and a Shell app. Boot continues, although a warning or prompt about Secure Boot policy-violating content may be shown to the user.', 'start_chunk': 34, 'end_chunk': 35}]}\n",
      "Trying Query 10\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'Where does the Snake installer store the kernel driver and custom DLL?', 'references': [{'content': 'Snake s installer drops the kernel driver and a custom DLL which is used to load the driver into a single AES encrypted file on disk. Typically, this file is named comadmin.dat and is stored in the %windows%\\\\system32\\\\Com directory.', 'start_chunk': 4, 'end_chunk': 6}, {'content': 'The key, IV, and path to comadmin.dat are stored in the encrypted registry blob.', 'start_chunk': 7, 'end_chunk': 8}]}\n",
      "Trying Query 11\n",
      "{'oath': 'I will not use the word \"and\" in the question unless it is part of a proper noun. I will also make sure the question is concise.', 'question': 'What built-in tools does the PRC state-sponsored cyber actor use to evade detection?', 'references': [{'content': 'Some of the built-in tools this actor uses are: wmic, ntdsutil, netsh, and PowerShell. The advisory', 'start_chunk': 33, 'end_chunk': 33}]}\n",
      "Trying Query 12\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What are the titles of the figures related to 5G Core Architecture in this document?', 'references': [{'content': 'Figure 2: 5G Core Architecture Containing the', 'start_chunk': 0, 'end_chunk': 0}, {'content': 'Figure 3: The Life Cycle of Service / Slice Instance Orchestration', 'start_chunk': 2, 'end_chunk': 2}, {'content': 'Figure 4: Network Slice', 'start_chunk': 3, 'end_chunk': 3}, {'content': 'Figure 5: Network Slice Model', 'start_chunk': 6, 'end_chunk': 6}, {'content': 'Figure 6: End-to-End 5G Network Slicing Architecture', 'start_chunk': 8, 'end_chunk': 8}]}\n",
      "Trying Query 13\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What is the current state of 5G network slicing implementations in relation to available standards?', 'references': [{'content': 'Existing 5G implementations do not fully realize the breadth of available standards.', 'start_chunk': 12, 'end_chunk': 13}, {'content': 'Current and future 5G standards do not and are unlikely to prescribe exactly how 5G standalone network slicing must or should be implemented.', 'start_chunk': 13, 'end_chunk': 14}, {'content': 'This will allow for network slicing to have varying implementations between infrastructure providers/vendors.', 'start_chunk': 14, 'end_chunk': 15}]}\n",
      "Trying Query 14\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What exfiltration techniques does an MCA employ to exploit a DevSecOps CI/CD cloud environment?', 'references': [{'content': 'Exfiltration\\nAutomated Exfiltration [T1020]\\nExfiltration\\nExfiltration Over C2 Channel [T1041]\\nExfiltration\\nExfiltration Over Alternative Protocol [T1048]\\nExfiltration\\nTransfer Data to Cloud Account [T1537]', 'start_chunk': 18, 'end_chunk': 21}]}\n",
      "Trying Query 15\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'How does BlackLotus leverage Baton Drop to compromise endpoint security?', 'references': [{'content': 'BlackLotus targets Windows boot by exploiting a flaw in older boot loaders to set off a chain of malicious actions that compromise endpoint security.', 'start_chunk': 10, 'end_chunk': 11}, {'content': 'Exploitation of Baton Drop (CVE-2022-21894) allows BlackLotus to strip the Secure Boot policy and prevent its enforcement.', 'start_chunk': 12, 'end_chunk': 13}]}\n",
      "Trying Query 16\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 16\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': \"What factors might influence North Korea's possible resumption of missile testing after the Beijing Winter Olympics?\", 'references': [{'content': 'with the Games in the books, speculation is growing that North Korea is likely to pick up where it left off in January, or a series of missile tests.', 'start_chunk': 2, 'end_chunk': 2}, {'content': \"China is scheduled to hold the National People's Congress, and the Chinese People's Political Consultative Conference from March 4 to 13 and do you think the schedule will further defer North Korea's possible missile testing?\", 'start_chunk': 6, 'end_chunk': 6}, {'content': 'North Korea has indicated that it will lift its moratorium on missile and nuclear tests, but do you think there is the possibility that Pyongyang will offer to talk with the U.S., putting the moratorium on the line?', 'start_chunk': 8, 'end_chunk': 8}]}\n",
      "Trying Query 17\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What key capabilities are associated with the maturity levels of the device pillar in Zero Trust?', 'references': [{'content': 'Device Inventory: Creating device inventory management systems and maintaining real time device inventories. Maintaining a trusted inventory list by enrolling all', 'start_chunk': 40, 'end_chunk': 42}]}\n",
      "Trying Query 18\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What examples of low-level persistent threats against devices are provided in the Zero Trust device pillar context?', 'references': [{'content': 'Past examples of low-level, persistent threats include: LoJax boot rootkit [4] MosaicRegressor firmware implant [5] UEFI Secure Boot bypasses BootHole [6] and BlackLotus [7] Side channel vulnerabilities such as Spectre, Meltdown, Fallout, ZombieLoad, NetSpectre, Downfall, and Inception SSD over-provisioning malware [8]', 'start_chunk': 12, 'end_chunk': 15}]}\n",
      "Trying Query 19\n",
      "{'oath': 'I will not use the word \"and\" in the question unless it is part of a proper noun. I will also make sure the question is concise.', 'question': 'What security best practices are recommended for MFA administrators?', 'references': [{'content': 'ed to a user, require additional authentication (e.g., with their password or a one-time secret provided out-of-band) as part of the enrollment process. Maintain an inventory of the authenticators deployed in your environment.', 'start_chunk': 0, 'end_chunk': 1}, {'content': 'Vulnerabilities may be discovered in both software and hardware authenticators, so it is critical to be able to identify authenticators in need of replacement or upgrade. Pay attention to vendor announcements and support lifecycles, and plan well in advance for any end-of-life authenticator solutions in need of replacement.', 'start_chunk': 2, 'end_chunk': 4}, {'content': 'have a response plan for lost or stolen authenticators or devices to rapidly disable the lost authenticator and enable the user to enroll a new one.', 'start_chunk': 7, 'end_chunk': 9}, {'content': 'Routinely test and rapidly patch your MFA infrastructure. This is good advice for any system or application, but it is especially critical for MFA and other authentication infrastructure.', 'start_chunk': 14, 'end_chunk': 16}, {'content': \"MFA can provide strong protection against many of the most prevalent attacks against authentication systems. Careful planning will help ensure that your MFA implementation meets your organization's needs and provides both security and usability.\", 'start_chunk': 25, 'end_chunk': 34}]}\n",
      "Trying Query 20\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What are the top cybersecurity misconfigurations identified in this document?', 'references': [{'content': 'Bypass of system access controls', 'start_chunk': 9, 'end_chunk': 10}, {'content': 'Weak or misconfigured MFA methods', 'start_chunk': 12, 'end_chunk': 13}, {'content': 'Lack of phishing-resistant MFA', 'start_chunk': 15, 'end_chunk': 16}, {'content': 'Insufficient ACLs on network shares and services', 'start_chunk': 17, 'end_chunk': 18}, {'content': 'Poor credential hygiene: easily crackable passwords', 'start_chunk': 20, 'end_chunk': 21}, {'content': 'Poor credential hygiene: cleartext password disclosure', 'start_chunk': 23, 'end_chunk': 24}, {'content': 'Unrestricted code execution', 'start_chunk': 25, 'end_chunk': 27}, {'content': 'Unrestricted code execution without administrator approval', 'start_chunk': 28, 'end_chunk': 30}]}\n",
      "Error occurred: The number of references exceeds 5.\n",
      "Trying Query 20\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: unterminated string literal (detected at line 4) (<unknown>, line 4)\n",
      "Trying Query 20\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What resources does Stairwell provide to identify Maui ransomware?', 'references': [{'content': 'Stairwell provided a YARA rule to identify Maui ransomware, and a Proof of Concept public RSA key extractor at the following link:\\nhttps://www.stairwell.com/news/threat-research-report-maui-ransomware/', 'start_chunk': 31, 'end_chunk': 32}]}\n",
      "Trying Query 21\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What threat involves an adversary substituting modified FPGA software design suites during synthesis, place and route, or configuration data generation?', 'references': [{'content': 'TD 7: Adversary substitutes modified FPGA software design suite In this threat, an adversary replaces the design suite an application designer uses with one modified to subvert the application during synthesis, place and route, or configuration data generation. In this threat, the adversary would have access to a modified version of commercial vendor software and would use the modified software Subvert the security features of an FPGA during configuration data generation. Insert a malicious function into the device during synthesis, place and route or configuration data generation. Insert a data leak or backdoor into the synthesized device during synthesis, place and route, or configuration data generation. This subverted tool would then be entered into the program', 'start_chunk': 28, 'end_chunk': 36}]}\n",
      "Trying Query 22\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 22\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'How does Snake encrypt parameter data in incoming commands?', 'references': [{'content': 'Snake uses the 0x227 RSA public key to decrypt the RSA blob, recover the CAST key, then decrypt the parameter data.', 'start_chunk': 7, 'end_chunk': 7}, {'content': 'For an incoming command, the CAST key is signed (not encrypted) by the private key corresponding to the public key on the node to create a 512-byte RSA data blob. The incoming payload has the RSA blob, followed by the optional parameter data, which is CAST-128 encrypted.', 'start_chunk': 5, 'end_chunk': 6}, {'content': 'Any response data was encrypted with the 0x228 CAST key.', 'start_chunk': 0, 'end_chunk': 1}, {'content': \"In recent versions, the 0x227 and 0x228 Items hold two RSA-4096 public keys. For each side of an exchange, a new 16-byte CAST key is created with Microsoft's CryptoAPI CryptGenRandom function to obtain 16 random bytes. This key is used to CAST-128 encrypt the parameter or response data.\", 'start_chunk': 1, 'end_chunk': 3}]}\n",
      "Trying Query 23\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 23\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What FPGA security measures are recommended for configuration data authentication?', 'references': [{'content': 'Authenticate configuration data each time the data is loaded into the FPGA device.', 'start_chunk': 3, 'end_chunk': 4}, {'content': 'Use a CNSS/NIST approved algorithm and key length. Otherwise use a NIST approved algorithm and key length, as described in the latest approved version of FIPS 186, Digital Signature Standard, or FIPS 198, The Keyed-Hash Message Authentication Code (HMAC).', 'start_chunk': 7, 'end_chunk': 8}, {'content': 'Prevent direct read back of the private keys through electrical means.', 'start_chunk': 5, 'end_chunk': 6}, {'content': 'The program can either select an authentication mechanism with an existing evaluation or sponsor the evaluation itself. JFAC can perform evaluations and maintains best practices in using commercial technology for this purpose.', 'start_chunk': 10, 'end_chunk': 11}, {'content': 'Authenticate all boot configuration data.', 'start_chunk': 14, 'end_chunk': 14}]}\n",
      "Trying Query 24\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 24\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What mitigations are described to protect against the introduction of a compromised design in FPGA applications?', 'references': [{'content': 'Physically isolate and store the application design until it is delivered.', 'start_chunk': 28, 'end_chunk': 29}, {'content': 'Perform reproducible build of the application.', 'start_chunk': 29, 'end_chunk': 30}]}\n",
      "Trying Query 25\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What specific mitigations are described for TD 3.1 in the context of FPGA applications?', 'references': [{'content': 'TD 3.1 Mitigating the introduction of a compromised design into the application In this scenario, the adversary is able to insert a Trojan into the design after the design has been verified, but before the design is loaded for final deployment. Strict controls on the revision control system will help prevent the adversary from making unmonitored changes.', 'start_chunk': 13, 'end_chunk': 15}, {'content': 'To protect against this, the program should store and isolate the verified configuration files, settings, and associated hashes. Before the design is loaded for final deployment, the program should verify the hash to ensure that the verified version is the same as what they are going to deploy. For extra assurance, the program has all the necessary data to reproduce the build and can verify the stored version against the reproduced version.', 'start_chunk': 20, 'end_chunk': 24}, {'content': 'Use a reproducible build process to verify the integrity of the FPGA synthesis and build software. The reproducible build performs the synthesis process that takes in human readable HDL, and other human readable inputs, and consistently generates the same final configuration file (bitstream). It is expected that this process will, in most cases, require the use of the same version of the Electronic Design Automation (EDA) tools, and in some cases the same operating system version. This process will highlight the possession of modified software where there is a mismatch.', 'start_chunk': 32, 'end_chunk': 40}]}\n",
      "Trying Query 26\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: unterminated string literal (detected at line 9) (<unknown>, line 9)\n",
      "Trying Query 26\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What are the main network slicing architectural approaches discussed in the document?', 'references': [{'content': 'modem-centric and OS-centric', 'start_chunk': 13, 'end_chunk': 14}, {'content': 'two OS-Centric scheme solutions, namely, changes to the operating system and Application APIs respectively.', 'start_chunk': 15, 'end_chunk': 16}, {'content': 'recommendation is to select modem centralization scheme which provide users with more diversified, flexible, and evolvable high-quality network slicing services.', 'start_chunk': 24, 'end_chunk': 25}, {'content': 'network slicing at the OS/Application layer provides greater flexibility and enhanced user experience at the same time.', 'start_chunk': 26, 'end_chunk': 27}]}\n",
      "Trying Query 27\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 27\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What D3FEND mitigations are described to counter Credential Access techniques?', 'references': [{'content': 'Application Configuration Hardening [D3-ACH]', 'start_chunk': 15, 'end_chunk': 15}, {'content': 'Multi-Factor Authentication [D3-MFA]', 'start_chunk': 16, 'end_chunk': 16}, {'content': 'One-time Password [D3-OTP]', 'start_chunk': 17, 'end_chunk': 17}, {'content': 'Credential Hardening [D3-CH]', 'start_chunk': 18, 'end_chunk': 18}, {'content': 'User Account Permissions [D3-UAP]', 'start_chunk': 18, 'end_chunk': 18}]}\n",
      "Trying Query 28\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'How could IAM auditing and monitoring have prevented the incident described in the example from September 2022?', 'references': [{'content': \"For example, in September 2022, an individual working as a cybersecurity professional in a Hawaiianbased financial company, pled guilty and admitted that, after severing ties with the company, he utilized the credentials of his former employer to gain access to the company website configuration settings and purposefully misdirected web and email traffic to computers unaffiliated with the company incapacitating the company's website and email. 23 IAM auditing and monitoring could have potentially prevented this by allowing the system to remove the user's access upon separation from the company.\", 'start_chunk': 18, 'end_chunk': 24}]}\n",
      "Trying Query 29\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 29\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'Why is the MANO system considered a highly sought-after target for compromising a 5G network slice?', 'references': [{'content': 'A very highly sought-after target for compromising a 5G network slice is attacking the MANO system. This is because the design, deployment, and operation of the slice will be done by the management platform, mostly via IaC, programmed automation playbooks, and orchestration of functions. Commandeering the MANO system enables the ability to introduce security configuration vulnerabilities that attackers can use to compromise the integrity of the network slice. The threats encompass unauthorized modifications of the pla', 'start_chunk': 36, 'end_chunk': 42}]}\n",
      "Trying Query 30\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What is Soft IP in the context of FPGA hardware design?', 'references': [{'content': 'Soft IP is a hardware design captured in hardware description language (HDL), intended to be integrated into a complete hardware design through a synthesis process. Soft IP can be distributed in a number of ways, as functional HDL or a netlist specified in HDL, encrypted or unencrypted.', 'start_chunk': 20, 'end_chunk': 22}]}\n",
      "Trying Query 31\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What low-level persistent threats against devices are addressed by Zero Trust capabilities?', 'references': [{'content': 'Past examples of low-level, persistent threats include: LoJax boot rootkit [4] MosaicRegressor firmware implant [5] UEFI Secure Boot bypasses BootHole [6] and BlackLotus [7] Side channel vulnerabilities such as Spectre, Meltdown, Fallout, ZombieLoad, NetSpectre, Downfall, and Inception SSD over-provisioning malware [8]', 'start_chunk': 18, 'end_chunk': 21}]}\n",
      "Trying Query 32\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: unterminated string literal (detected at line 13) (<unknown>, line 13)\n",
      "Trying Query 32\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 32\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What specific files of SQL Server did the SVR show interest in exfiltrating?', 'references': [{'content': 'C:\\\\Program Files\\\\Microsoft SQL Server\\\\MSSQL14.MSSQLSERVER\\\\MSSQL\\\\Binn\\\\sqlmin.dll,', 'start_chunk': 18, 'end_chunk': 19}, {'content': 'C:\\\\Program Files\\\\Microsoft SQL Server\\\\MSSQL14.MSSQLSERVER\\\\MSSQL\\\\Binn\\\\sqllos.dll,', 'start_chunk': 19, 'end_chunk': 20}, {'content': 'C:\\\\Program Files\\\\Microsoft SQL Server\\\\MSSQL14.MSSQLSERVER\\\\MSSQL\\\\Binn\\\\sqllang.dll,', 'start_chunk': 20, 'end_chunk': 21}, {'content': 'C:\\\\Program Files\\\\Microsoft SQL Server\\\\MSSQL14.MSSQLSERVER\\\\MSSQL\\\\Binn\\\\sqltses.dll', 'start_chunk': 21, 'end_chunk': 22}, {'content': 'C:\\\\Program Files\\\\Microsoft SQL Server\\\\MSSQL14.MSSQLSERVER\\\\MSSQL\\\\Binn\\\\secforwarder.dll', 'start_chunk': 22, 'end_chunk': 23}]}\n",
      "Trying Query 33\n",
      "{'oath': 'I will not use the word \"and\" in the question unless it is part of a proper noun. I will also make sure the question is concise.', 'question': 'What are the common security risks in CI/CD pipelines?', 'references': [{'content': 'Insecure first-party code: Code that is checked in by authorized developers but that contains security-related bugs that are not detected by either the software developers or by security tooling.', 'start_chunk': 3, 'end_chunk': 4}, {'content': 'Insecure third-party code: Insecure code that is compiled into a CI/CD pipeline from a third-party source, such as an open source project.', 'start_chunk': 5, 'end_chunk': 6}, {'content': 'Poisoned pipeline execution: Exploitation of a development/test/production environment that allows the attacker to insert code of its choosing.', 'start_chunk': 7, 'end_chunk': 8}, {'content': 'Insufficient pipeline access controls: Unauthorized access to source code repositories or build tools.', 'start_chunk': 9, 'end_chunk': 10}, {'content': 'Insecure system configuration: Various infrastructure, network, and application configurations vulnerable to known exploitation techniques.', 'start_chunk': 10, 'end_chunk': 11}, {'content': 'Usage of insecure third-party services: Using services created by an external individual or organization that intentionally or negligently includes security vulnerabilities.', 'start_chunk': 11, 'end_chunk': 12}, {'content': 'Exposure of secrets: Security key compromise and insecure secrets management within the pipeline, such as hardcoding access keys or passwords into infrastructure as code (laC) templates.', 'start_chunk': 13, 'end_chunk': 14}]}\n",
      "Error occurred: The number of references exceeds 5.\n",
      "Trying Query 33\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What techniques do malicious actors use to obtain login credentials?', 'references': [{'content': 'Impersonate supervisors, trusted colleagues, or IT personnel to send targeted emails to deceive employees into providing their login credentials.', 'start_chunk': 8, 'end_chunk': 9}, {'content': 'Use smartphones or tablets, along with short message system (SMS), to send text messages or chats in platforms such as Slack, Teams, Signal, WhatsApp, or Facebook Messenger to lure users into divulging their login credentials.', 'start_chunk': 9, 'end_chunk': 11}, {'content': 'Use voice over internet protocol (VoIP) to easily spoof caller identification (ID) which takes advantage of public trust in the security of phone services, especially landline phones.', 'start_chunk': 15, 'end_chunk': 17}, {'content': \"SMS or voice MFA. Malicious actors can convince cellular carrier representatives to transfer control of a user's phone number to receive any SMS or call-based MFA codes.\", 'start_chunk': 26, 'end_chunk': 28}]}\n",
      "Trying Query 34\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What are the primary purposes for which cyber threat actors use remote access software?', 'references': [{'content': 'Threat actors use remote access software for initial access, maintaining persistence, deploying additional software and tools, lateral movement, and data exfiltration.', 'start_chunk': 19, 'end_chunk': 20}, {'content': 'Threat actors use remote access software to perform multiple functions and carry out several commonly associated TTPs (e.g., credential dumps and escalating privileges.)', 'start_chunk': 34, 'end_chunk': 35}]}\n",
      "Trying Query 35\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 35\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 35\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What specific steps are required to revoke signed EFI executables in UEFI Secure Boot?', 'references': [{'content': 'Revoking signed EFI executables requires updating the DBX.', 'start_chunk': 5, 'end_chunk': 5}, {'content': '1. Identify specific EFI binaries that need to be revoked.', 'start_chunk': 7, 'end_chunk': 7}, {'content': '2. Calculate hashes for the EFI binaries. Note that tools aware of Portable Executable (PE/EFL) format must be used.', 'start_chunk': 7, 'end_chunk': 8}, {'content': '3. If your BIOS, UEFI configuration, or remote management tool accepts hashes, then submit them.', 'start_chunk': 12, 'end_chunk': 12}, {'content': '4. If hash files were not sufficient, then create ESL files. Try to load the ESL files.', 'start_chunk': 12, 'end_chunk': 13}, {'content': '5. If the ESL files are rejected, it is likely due to a lack of signature. Follow instructions in section 4.3.1 to create a key and certificate used when signing ESL files.', 'start_chunk': 14, 'end_chunk': 15}, {'content': '6. Use the new certificate and key to sign ESL files into AUTH files.', 'start_chunk': 16, 'end_chunk': 16}, {'content': '7. Install the new hashes and possibly the new certificate following instructions in section 4.3.4.', 'start_chunk': 17, 'end_chunk': 17}]}\n",
      "Error occurred: The number of references exceeds 5.\n",
      "Trying Query 35\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 35\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 35\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 35\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'How many satellite locations did the NSA Cybersecurity Collaboration Center expand to in 2022?', 'references': [{'content': 'This year, the CCC expanded to four new satellite locations: Georgia, Texas, Hawaii, and the United Kingdom.', 'start_chunk': 4, 'end_chunk': 5}]}\n",
      "Trying Query 36\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 36\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 36\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 36\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 36\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: unterminated string literal (detected at line 13) (<unknown>, line 13)\n",
      "Trying Query 36\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What are the high-level security objectives for E2E 5G network slicing?', 'references': [{'content': '1) Ensure availability of the network slice user data in transit as required by the NSC.', 'start_chunk': 1, 'end_chunk': 1}, {'content': '2) Ensure integrity of network slice user data in transit as required by the NSC.', 'start_chunk': 2, 'end_chunk': 2}, {'content': '3) A network slice must enforce the physical and logical constraints on its path over its lifetime.', 'start_chunk': 3, 'end_chunk': 3}, {'content': '4) A network slice must ensure confidentiality of data in transit as required by its SLRs.', 'start_chunk': 4, 'end_chunk': 4}, {'content': '5) Ensure confidentiality of the owner of the network slice user data in transit as required by the network slice customers.', 'start_chunk': 5, 'end_chunk': 5}]}\n",
      "Trying Query 37\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What are the TD 6 mitigations for FPGA configuration security?', 'references': [{'content': 'Incorporate cryptographic authentication of all loaded configuration data as part of the system containing the FPGA.', 'start_chunk': 2, 'end_chunk': 3}, {'content': 'Design the system to authenticate configuration data each time the data is loaded into the FPGA device.', 'start_chunk': 3, 'end_chunk': 4}, {'content': 'Configure all production devices in a way that prevents direct read back of the private keys through electrical means.', 'start_chunk': 5, 'end_chunk': 6}, {'content': 'Use a CNSS/NIST approved algorithm and key length.', 'start_chunk': 6, 'end_chunk': 7}, {'content': 'Disable test access pins in fielded products.', 'start_chunk': 7, 'end_chunk': 8}]}\n",
      "Trying Query 38\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'How many threat descriptions are addressed in this report?', 'references': [{'content': 'Threat description (TD) TD 1 Adversary utilizes a known FPGA platform vulnerability', 'start_chunk': 34, 'end_chunk': 34}, {'content': 'TD 2 Adversary inserts malicious counterfeit TD 3 Adversary compromises application design cycle', 'start_chunk': 35, 'end_chunk': 35}, {'content': 'TD 4 Adversary compromises system assembly, keying, or provisioning TD 5 Adversary compromises third-party soft intellectual property (IP)', 'start_chunk': 36, 'end_chunk': 36}, {'content': 'TD 6 Adversary swaps configuration file on target TD 7 Adversary substitutes modified FPGA software design suite', 'start_chunk': 37, 'end_chunk': 37}, {'content': 'TD 8 Adversary modifies FPGA platform family at design TD 9 Adversary compromises single-board', 'start_chunk': 39, 'end_chunk': 41}]}\n",
      "Trying Query 39\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 39\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'How do identity governance systems reduce risks associated with identity and privilege mismanagement?', 'references': [{'content': \"They provide a comprehensive view of an organization's identity management practices and identify gaps in the identity management lifecycle.\", 'start_chunk': 0, 'end_chunk': 2}, {'content': 'Identity governance systems maintain an inventory of active accounts and privileges that currently exist in systems and applications, enabling monitoring and analysis.', 'start_chunk': 4, 'end_chunk': 6}, {'content': 'Policy rules can be created for segregation of duties requirements, enabling administrators to identify and remove non-compliant combinations of privileges assigned to individuals.', 'start_chunk': 7, 'end_chunk': 8}, {'content': \"Automated risk analysis can identify high-risk individuals so that appropriate mitigations can be taken, such as re-assigning privileges or elevated monitoring of those users' accounts.\", 'start_chunk': 9, 'end_chunk': 10}, {'content': 'Together, these processes support the principle of Least Privilege, ensuring that users have only the privileges required for their job functions.', 'start_chunk': 12, 'end_chunk': 13}]}\n",
      "Trying Query 40\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'Where did the NSA Cybersecurity Collaboration Center expand to in 2022?', 'references': [{'content': 'In late 2020, NSA opened the Cybersecurity Collaboration Center, an unclassified facility outside the NSA-Washington fence line. This year, the CCC expanded to four new satellite locations: Georgia, Texas, Hawaii, and the United Kingdom.', 'start_chunk': 8, 'end_chunk': 9}]}\n",
      "Trying Query 41\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 41\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid decimal literal (<unknown>, line 5)\n",
      "Trying Query 41\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What IAM threat mitigation tactics are discussed in the paper?', 'references': [{'content': 'The best practices and mitigations discussed in this paper provide tactics that help to counter threats to IAM through deterrence, prevention, detection, damage limitation, and response.', 'start_chunk': 12, 'end_chunk': 14}]}\n",
      "Trying Query 42\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What security recommendations are made for network slice implementation?', 'references': [{'content': 'Logical isolation and performance isolation between network slices. Physical isolation of physical resources for network slices, and separate management systems and administrators will be required to meet high confidentiality, integrity, and availability triad requirements.', 'start_chunk': 23, 'end_chunk': 24}, {'content': 'Usage-specific security policies regarding authentication and authorization requirements (e.g., IoT vs. mobile broadband user) must be configurable.', 'start_chunk': 31, 'end_chunk': 32}, {'content': 'Slice-specific authentication that is performed over and above the 3GPP primary authentication is carried out to meet customer user authentication requirements.', 'start_chunk': 33, 'end_chunk': 34}, {'content': 'Network Slice and the provider take into consideration privacy of user information and device identifiers, including following regulations like Customer Proprietary Network Information (CPNI).', 'start_chunk': 35, 'end_chunk': 35}]}\n",
      "Trying Query 43\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 43\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What methods do Kimsuky actors use in their email communications to trick targets?', 'references': [{'content': 'Kimsuky actors impersonate researchers from legitimate South Korean think tanks to send spearphishing emails to political and North Korean experts.', 'start_chunk': 30, 'end_chunk': 31}, {'content': 'Once an initial response is received, actors will request an email interview with a list of questions and request that targets access documents via a malicious link to a cloud-hosted service.', 'start_chunk': 18, 'end_chunk': 19}, {'content': 'They initiate communication by sending genuine emails to establish rapport and seek opinions on various topics, such as North Korea foreign policy and our response.', 'start_chunk': 31, 'end_chunk': 32}]}\n",
      "Trying Query 44\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What cybersecurity resources are cited in this document?', 'references': [{'content': 'CISA, Secure Cloud Business Applications (SCuBA) Project, https://www.cisa.gov/resourcestools/services/secure-cloud-business-applications-scuba-project', 'start_chunk': 1, 'end_chunk': 1}, {'content': 'NSA, Transition to Multi-factor Authentication, https://media.defense.gov/2019/Sep/09/2002180346/-1/-1/0/Transition%20to%20Multifact%20Authentication%20-%20Copy.pdf', 'start_chunk': 3, 'end_chunk': 4}, {'content': 'Committee on National Security Systems (CNSS), CNSS Policy 15, https://www.cnss.gov/CNSS/issuances/Policies.cfm', 'start_chunk': 5, 'end_chunk': 5}, {'content': 'NSA, NSA Releases Future Quantum-Resistant (QR) Algorithm Requirements for National Security Systems, https://www.nsa.gov/Press-Room/NewsHighlights/Article/Article/3148990/nsa-releases-future-quantum-re%20sistant-qr-algorithmrequirements-for-national-se/', 'start_chunk': 7, 'end_chunk': 8}]}\n",
      "Trying Query 45\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What Zero Trust reviews did NSA provide in the past year?', 'references': [{'content': 'Within the past year, NSA provided Zero Trust reviews and implementation roadmaps for two critical systems for the Navy and Air Force. The products were the result of enduring collaboration with the Navy and Air Force throughout the year.', 'start_chunk': 31, 'end_chunk': 33}]}\n",
      "Trying Query 46\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What is the CVSS score for CVE-2021-44228, and which versions of Apache Log4j2 are affected?', 'references': [{'content': 'CVE-2021-44228 CVSS 3.0: 10 (Critical)', 'start_chunk': 32, 'end_chunk': 32}, {'content': 'Apache Log4j2 2.0-beta9 through 2.15.0 (excluding security releases 2.12.2, 2.12.3, and 2.3.1) JNDI features used in configuration, log messages, and parameters do not protect against attacker controlled LDAP and other JNDI related endpoints.', 'start_chunk': 33, 'end_chunk': 34}, {'content': 'From log4j 2.15.0, this behavior has been disabled by default. From version 2.16.0 (along with 2.12.2, 2.12.3, and 2.3.1), this functionality has been completely removed.', 'start_chunk': 37, 'end_chunk': 38}]}\n",
      "Trying Query 47\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': \"Where are the Cybersecurity Collaboration Center's satellite locations?\", 'references': [{'content': 'This year, the CCC expanded to four new satellite locations: Georgia, Texas, Hawaii, and the United Kingdom.', 'start_chunk': 27, 'end_chunk': 28}]}\n",
      "Trying Query 48\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What types of network monitoring activities are described for 5G networks?', 'references': [{'content': 'Types of Network Monitoring Performance Management Quality of Service NIST 5G Cybersecurity Control Plane Communication User-Plane Communication Anomaly Detection', 'start_chunk': 24, 'end_chunk': 25}, {'content': 'Performance Management Due to the complex nature of mobile networks and vendors diversity of hosting platforms, a unique overarching performance management technique across different networks and vendors is required', 'start_chunk': 26, 'end_chunk': 27}, {'content': '5G QoS include network performance metrics (e.g., latency, throughput, etc.) but might also include availability, reliability, accessibility, retainability, etc.', 'start_chunk': 28, 'end_chunk': 29}, {'content': 'NIST SP1800-33B provides examples of 5G standard features and third-party security controls for successful 5G implementations.', 'start_chunk': 30, 'end_chunk': 31}, {'content': 'Control plane communication is not only protected for privacy but also protected against attacker malicious modifications, performance issues, and anomalous behaviors. This is the communication which connects the actual data coming over the RAN to the Internet which is helpful to detect acceptable use violations e.g., a DDoS attack, DNS tunneling, spoofing, etc.', 'start_chunk': 31, 'end_chunk': 33}, {'content': 'Anomaly detection is a capability of identifying unusual activities or behaviors in networks. A variety of sensors, filtering and advanced (e.g., AI/ML-based) security analytics are necessary to detect sophisticated and zero-day threats.', 'start_chunk': 35, 'end_chunk': 36}]}\n",
      "Error occurred: The number of references exceeds 5.\n",
      "Trying Query 48\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 48\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 48\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 48\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What types of endpoints can XDR solutions correlate artifacts from?', 'references': [{'content': 'XDR platforms further increase visibility and detection of cross-device threats by enabling the correlation of artifacts from endpoints that differ in design, location, or hardware.', 'start_chunk': 9, 'end_chunk': 10}]}\n",
      "Trying Query 49\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What is the required clearance level for personnel performing designated work in FPGA security?', 'references': [{'content': 'Use cleared personnel that possess at least a Secret level clearance. *Research vulnerabilities affecting tools/platforms.', 'start_chunk': 9, 'end_chunk': 10}, {'content': 'Use personnel with at least a Secret clearance to perform designated work. Designated work could include design reviews, peer reviews, vulnerability research, validation, and verification activities, etc.', 'start_chunk': 21, 'end_chunk': 22}]}\n",
      "Trying Query 0\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What actions does the Pitty Tiger malware take after execution?', 'references': [{'content': 'The binary drops a copy of itself in the Application Data folder of the currently logged-in user:', 'start_chunk': 8, 'end_chunk': 9}, {'content': 'The malware initiates a communication to time.windows.com to check for connectivity, and then communicates with the c&c server at mac.avstore.com.tw.', 'start_chunk': 10, 'end_chunk': 11}]}\n",
      "Trying Query 1\n",
      "{'oath': 'I will not use the word \"and\" in the question unless it is part of a proper noun. I will also make sure the question is concise.', 'question': 'What steps does the Loader take to handle the embedded DLL?', 'references': [{'content': 'The Loader stores the embedded DLL within a Group Icon resource within a legitimate icon image. In order to locate the embedded DLL, LoadEmbeddedImage will use the DecodeString function to decrypt the delimiter string (which is typically zzzzzzzzzz yyyyyyyyyyy) and then search the icon resource memory for the delimiter string.', 'start_chunk': 3, 'end_chunk': 5}, {'content': 'Once located, LoadEmbeddedImage will use the first 12 bytes immediately after the string as the information structure about the embedded DLL. The structure defines the size of the embedded DLL within the icon resource memory, the size of the DLL after it is decompressed and a 4-byte XOR key that LoadEmbeddedImage must use to decode the embedded DLL prior to decompression.', 'start_chunk': 6, 'end_chunk': 8}, {'content': 'LoadEmbeddedImage copies the compressed embedded DLL into a newly allocated heap buffer and then calls the function decodeBuffer (using the EncodingKey value) to decrypt the embedded DLL. Another heap buffer is allocated with a size equal to the value of dwImageSizeDecompressed.', 'start_chunk': 12, 'end_chunk': 14}, {'content': 'decompression buffer along with the now decoded compressed buffer are given to lzo_decompress which decompresses the compressed image using the LZO1X algorithm.', 'start_chunk': 15, 'end_chunk': 16}, {'content': 'With the embedded DLL now decompressed into a heap buffer, LoadEmbeddedImage calls ImageLoaderData::LoadDll to manually load the DLL into memory.', 'start_chunk': 17, 'end_chunk': 18}]}\n",
      "Trying Query 2\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'Which regions are linked to defense attacks?', 'references': [{'content': 'South Korea', 'start_chunk': 3, 'end_chunk': 3}, {'content': 'Mexico', 'start_chunk': 13, 'end_chunk': 13}, {'content': 'China', 'start_chunk': 15, 'end_chunk': 15}, {'content': 'EU', 'start_chunk': 19, 'end_chunk': 19}]}\n",
      "Trying Query 3\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What motivation does ISIS have for using social engineering or malware to locate RSS members?', 'references': [{'content': 'ISIS has a strong motivation for using social engineering and/or malware to locate the members of RSS.', 'start_chunk': 31, 'end_chunk': 32}]}\n",
      "Trying Query 4\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 4\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 4\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 4\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 4\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What methods does the malware use to stay stealthy?', 'references': [{'content': 'code suggests that even file system and registry operations can be delegated by an infected module', 'start_chunk': 0, 'end_chunk': 0}, {'content': 'to another module in order to stay unnoticed by behaviour analysis engines of the antivirus', 'start_chunk': 1, 'end_chunk': 1}, {'content': 'products, and to overcome account restrictions of the browser processes so that the injected module', 'start_chunk': 2, 'end_chunk': 2}, {'content': 'could still write into files and into the sensitive registry hives. The logs and dumps it creates', 'start_chunk': 3, 'end_chunk': 3}, {'content': 'on the hidden virtual volumes contributes to its stealthiness too. A great deal of attention has', 'start_chunk': 4, 'end_chunk': 4}, {'content': 'also been given to keep its network communications as quiet as possible. Its ability to generate', 'start_chunk': 5, 'end_chunk': 5}, {'content': 'malicious traffic whenever the user goes online and start loading the web pages allows it to', 'start_chunk': 6, 'end_chunk': 6}]}\n",
      "Error occurred: The number of references exceeds 5.\n",
      "Trying Query 4\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 4\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 4\n",
      "{'oath': 'I will not use the word \"and\" in the question unless it is part of a proper noun. I will also make sure the question is concise.', 'question': 'What are the primary sections or topics covered in the provided HP Security Briefing?', 'references': [{'content': 'Profiling an enigma: The mystery of North Korea s cyber threat landscape', 'start_chunk': 6, 'end_chunk': 7}, {'content': 'North Korean cyber capabilities and limitations', 'start_chunk': 19, 'end_chunk': 19}, {'content': 'North Korean infrastructure', 'start_chunk': 22, 'end_chunk': 22}, {'content': 'North Korean cyber war and intelligence structure', 'start_chunk': 25, 'end_chunk': 25}, {'content': 'Cyber warfare operations', 'start_chunk': 31, 'end_chunk': 31}]}\n",
      "Trying Query 5\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 5\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What programming language was used to develop the 3PARA RAT?', 'references': [{'content': 'The RAT is programmed in C++ using Microsoft Visual Studio, and it makes use of the object-oriented and parallel programming features of this environment; Standard Template Library (STL) objects are used to represent data structures such as strings and lists, and custom objects are used to represent some of the C2 command handlers (e.g., CCommandCMD).', 'start_chunk': 17, 'end_chunk': 19}]}\n",
      "Trying Query 6\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What method do attackers use to load Java Native Interface (JNI) code into host apps, and what actions can they perform with it?', 'references': [{'content': 'Fortunately, Android Runtime offers another way to load Java Native Interface (JNI) code into the host app using Runtime.load(). As shown in Listing 5, an attacker can load executables compiled from JNI code.', 'start_chunk': 19, 'end_chunk': 21}, {'content': 'Once loaded, the code can obtain context as described in Listing 4, or call DexClassLoaderload12 to inject new classes from the attackers files to register callbacks to take pictures/record videos.', 'start_chunk': 26, 'end_chunk': 28}]}\n",
      "Trying Query 7\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: unterminated string literal (detected at line 9) (<unknown>, line 9)\n",
      "Trying Query 7\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What methods were used to identify FinSpy servers?', 'references': [{'content': 'In response to a request such as GET /, the Bahraini FinSpy C&C server returns a response with the string Hallo Steffi [67]. Guarnieri searched a database of such responses compiled by the Critical.IO Internet scanning project [68], locating 11 additional servers in 10 countries [67].', 'start_chunk': 24, 'end_chunk': 27}, {'content': 'We devised our own fingerprint 1 that tested three aspects of the handshake between a FinSpy infectee and a FinSpy C&C server, which follows a custom TLV-based protocol running on ports such as 22, 53, 80, and 443. We conducted targeted scanning of several countries using 1, and also confirmed Guarnieri’s findings for those servers still reachable after he published his findings.', 'start_chunk': 28, 'end_chunk': 30}]}\n",
      "Trying Query 8\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What is the relationship between APT28 malware compile times and the time zone of major Russian cities?', 'references': [{'content': \"Malware Compile Times Correspond to Work Day in Moscow's Time Zone Consistent among APT28 samples with compile times from 2007 to 2014 The compile times align with the standard workday in the UTC + 4 time zone which includes major Russian cities such as Moscow and St. Petersburg\", 'start_chunk': 26, 'end_chunk': 28}]}\n",
      "Trying Query 9\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'How did the threat described in the report continue despite public disclosure?', 'references': [{'content': 'However, the operation behind the attacks has continued with little modification to the tools and techniques, in spite of the widespread attention a few years ago.', 'start_chunk': 34, 'end_chunk': 35}, {'content': 'There are some threats which come and go, whilst there are others which are permanent features of the landscape. In this paper, we describe the tools and techniques of one of the most sophisticated and persistent threa', 'start_chunk': 39, 'end_chunk': 40}]}\n",
      "Trying Query 10\n",
      "{'oath': 'I will not use the word \"and\" in the question unless it is part of a proper noun. I will also make sure the question is concise.', 'question': 'How does the driver implement network stack hooking?', 'references': [{'content': 'The driver obtains the device object by using IoGetDeviceObjectPointer() and hooks Major Function 14 the IRP_MJ_DEVICE_CONTROL, as this is the function through which all Input Output ConTroLls (IOCTLs) are sent, such as the IOCTL for querying active IP connections.', 'start_chunk': 20, 'end_chunk': 22}, {'content': 'The NSI hook, targets IOCTL 0x12001B, which is used by NsiGetObjectAllParameters() in nsi.dll when users typically run commands such as netstat.exe or use any of the IP Helper APIs in iphlpapi.dll. The purpose of the hook is to scan the list of active connections returned to the user, and hide any such connection currently bound to a local TCP port in the range between 40000 and 45000.', 'start_chunk': 23, 'end_chunk': 26}, {'content': 'The TCP hook works almost identically to the NSI hook, though instead hooking IOCTL 0x120003 (IOCTL_ any connections listening on TCP ports in the range between 40000 and 45000.', 'start_chunk': 38, 'end_chunk': 40}]}\n",
      "Trying Query 11\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 11\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: unterminated string literal (detected at line 3) (<unknown>, line 3)\n",
      "Trying Query 11\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What assembly instructions are present in the provided text?', 'references': [{'content': 'push\\ncall\\ntest\\n                      ject\\n           ', 'start_chunk': 18, 'end_chunk': 18}, {'content': 'mov\\n mov\\n cmp\\n        ', 'start_chunk': 22, 'end_chunk': 22}, {'content': 'mov\\n                           p\\n                      jnz\\n                           ', 'start_chunk': 23, 'end_chunk': 23}]}\n",
      "Trying Query 12\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What were the effects of temperature on the reaction rate in Experiment A?', 'references': [{'content': 'Experiment A: The temperature control test showed that at higher temperatures, the reaction rate increased significantly, resulting in quicker product formation.', 'start_chunk': 0, 'end_chunk': 0}, {'content': 'at extremely high temperatures, the reaction yield decreased due to the degradation of reactants.', 'start_chunk': 1, 'end_chunk': 1}]}\n",
      "Trying Query 13\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: unterminated string literal (detected at line 6) (<unknown>, line 6)\n",
      "Trying Query 13\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What malware families are identified in the provided text along with their associated strings?', 'references': [{'content': 'PittyTiger RAT', 'start_chunk': 2, 'end_chunk': 2}, {'content': 'CT RAT', 'start_chunk': 19, 'end_chunk': 19}, {'content': 'Paladin RAT', 'start_chunk': 16, 'end_chunk': 16}, {'content': 'MM RAT (aka Troj/Goldsun-B)', 'start_chunk': 22, 'end_chunk': 22}, {'content': 'Troj/ReRol.A', 'start_chunk': 8, 'end_chunk': 8}]}\n",
      "Trying Query 14\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'Where are Stage 2 and Stage 3 of Regin stored?', 'references': [{'content': 'Stage 2 finds and loads an encrypted version of Stage 3 from either NTFS extended attributes or a registry key blob.', 'start_chunk': 4, 'end_chunk': 5}, {'content': 'Stage 3 can be found in the following locations: Extended attribute %Windir%\\\\system32 %Windir%\\\\system32\\\\drivers Registry subkey HKEY_LOCAL_MACHINE\\\\SYSTEM\\\\CurrentControlSet\\\\Control\\\\Class\\\\{4F20E605-9452-4787-B793-', 'start_chunk': 16, 'end_chunk': 17}, {'content': 'Registry subkey HKEY_LOCAL MACHINE\\\\SYSTEM\\\\CurrentControlSet\\\\Control\\\\Class\\\\{4F20E605-9452-4787-B793-', 'start_chunk': 18, 'end_chunk': 19}]}\n",
      "Trying Query 15\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What specific entities were targeted in the March 20, 2013 DarkSeoul attacks, and what type of malware was used?', 'references': [{'content': 'A March 20, 2013 attack attributed to the DarkSeoul actors targeted three South Korean media outlets and Shinhan, Nonghyup, and Jeju banks.', 'start_chunk': 16, 'end_chunk': 18}, {'content': 'The malware used in the March 20, 2013 attacks were wiper malware. The malware attempted to disable AhnLab and Hauri AV antivirus products then proceeded to overwrite the master boot record (MBR). The attack was capable of wiping both Linux and Windows machines.', 'start_chunk': 38, 'end_chunk': 40}]}\n",
      "Trying Query 16\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What decryption sequences and algorithms do the SOURFACE, CORESHELL, and EVILTOSS malware families use for string encoding and decoding?', 'references': [{'content': 'CORESHELL, CHOPSTICK, and EVILTOSS Figure 6: Typical deployment of SOURFACE ecosystem', 'start_chunk': 2, 'end_chunk': 3}, {'content': 'Two of the malware families (SOURFACE/CORESHELL and EVILTOSS) use the same decryption sequence and similar algorithms for string encoding and decoding.', 'start_chunk': 13, 'end_chunk': 15}]}\n",
      "Trying Query 17\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What inconsistencies were observed in the Tranchulas response?', 'references': [{'content': 'Inconsistency #1: Day & Date Misalignment within image1.png Screenshot Our review of the Response_ThreatConnect.docx focused in on the email screenshot (Figure 3) image1.png that Khan provided revealing that the date probably had been modified to appear as though they were the first to notify VPSNOC.', 'start_chunk': 12, 'end_chunk': 16}, {'content': 'Inconsistency #2: Awareness of Withheld Information The email screenshot (image1.png) from within the Tranchulas response demonstrated awareness of information that we initially withheld and later released in our blog post: one malware variant that contained a debug string with umairaziz27 the same username as a Tranchulas employee.', 'start_chunk': 29, 'end_chunk': 33}, {'content': 'Inconsistency #3: Tranchulas Direct Notification The Tranchulas response indicates that Tranchulas research team was already aware of this incident before publication of this report. Our team contacted hosting company of server to seek an explanation.', 'start_chunk': 38, 'end_chunk': 40}]}\n",
      "Trying Query 18\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What subdomains of skypetm.com.tw are linked to specific malware types?', 'references': [{'content': 'sophos.skypetm.com.tw Troj/ReRol.A', 'start_chunk': 2, 'end_chunk': 3}, {'content': 'asdf.skypetm.com.tw Backdoor:Win32/Ptiger.A', 'start_chunk': 14, 'end_chunk': 15}, {'content': 'newb02.skypetm.com.tw CT RAT', 'start_chunk': 8, 'end_chunk': 9}, {'content': 'margo.skypetm.com.tw Rerol.A', 'start_chunk': 12, 'end_chunk': 12}, {'content': 'ripper.skypetm.com.tw Backdoor:Win32/Ptiger.A', 'start_chunk': 13, 'end_chunk': 13}]}\n",
      "Trying Query 19\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 19\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 19\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 19\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 19\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What are the key features of Red Star OS?', 'references': [{'content': 'The development of this Linux-based operating system started in 2002. Red Star OS is only offered in the Korean language and features proprietary software including Naenara (a Firefox-based browser), as well as a text editor, email client, audio and video players, and games.80 Red Star OS keyboard layouts include Korean, English, Russian, Chinese, and Japanese. Regime ideals extend to Red Star OS. The readme file, which goes with the installation disc, reportedly includes a quote from Kim Jong-Il regarding the importance of North Korea having its own Linux-based operating system that is compatible with Korean traditions.', 'start_chunk': 19, 'end_chunk': 24}, {'content': 'While prior versions of Red Star were KDE-based, version 3.0 mimics Apple s OS X.81 82 This could indicate the regime leader Kim Jong Un s preference for the OS X environment, as Kim reportedly uses an iMac.83', 'start_chunk': 26, 'end_chunk': 28}, {'content': 'The OS s design suggests it was developed with means for the regime to monitor user activity.85', 'start_chunk': 29, 'end_chunk': 30}]}\n",
      "Trying Query 20\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 20\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What server groups were identified in specific countries, along with the malware samples they communicated with?', 'references': [{'content': 'Turkey: We identified a group containing 20 servers in 9 countries. Two RCS and 5 FSBSpy samples from VirusTotal communicated with various servers in the group. The RCS samples also communicated with domains with lapsed registrations, so we registered them to observe incoming traffic. We exclusively received RCS traffic from Turkish IP addresses. (RCS traffic is identifiable based on a distinctive user agent and URL in POST requests.) A sample of FSBSpy apparently installed from an exploit on a Turkish server talked to one of the servers in this group.', 'start_chunk': 10, 'end_chunk': 16}, {'content': 'We also found server groups containing servers in Uzbekistan and Kazakhstan; we found FSBSpy samples on VirusTotal uploaded from these countries that communicated with servers in these groups.', 'start_chunk': 23, 'end_chunk': 26}]}\n",
      "Trying Query 21\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 21\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What improvements are expected if the attackers continue their current operations?', 'references': [{'content': 'that if these actors continue the current pace of their operations they will improve their capabilities in the mid-term.', 'start_chunk': 5, 'end_chunk': 5}, {'content': 'believe that if these actors continue the current pace of their operations they will improve their capabilities in the mid-term.', 'start_chunk': 4, 'end_chunk': 4}]}\n",
      "Trying Query 22\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What is Cylance and what services does it offer?', 'references': [{'content': 'Today, McClure is CEO of Cylance, a disruptive and innovative startup applying math to the problem of security.', 'start_chunk': 4, 'end_chunk': 5}, {'content': 'Cylance products such as CylancePROTECT prevent the most advanced attacks in the world without signatures or sandboxing in realtime on the endpoint. Cylance Services offer highly specialized security services such as incident response, forensics, compromise assessments and advanced penetration assessments for global critical infrastructure.', 'start_chunk': 5, 'end_chunk': 8}, {'content': 'Cylance employees work passionately and tirelessly every day to achieve one goal: Protect the world from cyber attacks. And with their efforts in tracking Operation Cleaver, they have achieved that goal.', 'start_chunk': 9, 'end_chunk': 11}, {'content': \"The Operation Cleaver logo, created by Cylance specifically for this report, was inspired by the infamous logo used by the Army of the Guardians of the Islamic Revolution, also known in the west as the Iranian Revolutionary Guard Corps (IRGC). Due to the close connection between the members tracked in this report and the IRGC, it was only fitting to replicate the look and feel of the IRGC's iconography as the anchor for this document's branding.\", 'start_chunk': 26, 'end_chunk': 30}]}\n",
      "Trying Query 23\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What specific details are included in the portable executable (PE) resource with the SHA256 hash 5156ACA994ECFCB40458EAD8C830CD66469D5F5A031392898D323A8D7A7F23D3?', 'references': [{'content': 'This PE resource contains the VS_VERSION_INFO. In layman terms, this can best be described as the metadata describing the executable file. This specific PE resource contained the following information: Note the InternalName of Stealer.exe. This is the attackers name for this malware family.', 'start_chunk': 35, 'end_chunk': 38}, {'content': 'This PE resource contains the VS_VERSION_INFO. In layman terms, this can best be described as the metadata describing the executable file. This specific PE resource contained the following information:', 'start_chunk': 37, 'end_chunk': 37}, {'content': 'Note the InternalName of Stealer.exe. This is the attackers name for this malware family.', 'start_chunk': 39, 'end_chunk': 39}]}\n",
      "Trying Query 24\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': \"What are the MD5 hashes associated with each instance of 'Lightweight backdoor' along with their unique compile times?\", 'references': [{'content': 'MD5: 7759c7d2c6d49c8b0591a3a7270a44da\\nCharacterization: File Hash Watchlist\\nNotes: \"Lightweight backdoor\"\\n     Earliest PE compile time: 20120309T105837Z\\n     Latest PE compile time: 20120309T105837Z', 'start_chunk': 0, 'end_chunk': 1}, {'content': 'MD5: 7e48d5ba6e6314c46550ad226f2b3c67\\nCharacterization: File Hash Watchlist\\nNotes: \"Lightweight backdoor\"\\n     Earliest PE compile time: 20120311T090329Z\\n     Latest PE compile time: 20120311T090329Z', 'start_chunk': 2, 'end_chunk': 3}, {'content': 'MD5: 0a87c6f29f34a09acecce7f516cc7fdb\\nCharacterization: File Hash Watchlist\\nNotes: \"Lightweight backdoor\"\\n     Earliest PE compile time: 20120325T053138Z\\n     Latest PE compile time: 20130513T090422Z', 'start_chunk': 4, 'end_chunk': 6}, {'content': 'MD5: 25fb1e131f282fa25a4b0dec6007a0ce\\nCharacterization: File Hash Watchlist\\nNotes: \"Lightweight backdoor\"\\n     Earliest PE compile time: 20130802T054822Z\\n     Latest PE compile time: 20130802T054822Z', 'start_chunk': 7, 'end_chunk': 8}, {'content': 'MD5: 9761dd113e7e6673b94ab4b3ad552086\\nCharacterization: File Hash Watchlist\\nNotes: \"Lightweight backdoor\"\\n     Earliest PE compile time: 20130913T013016Z\\n     Latest PE compile time: 20130913T013016Z', 'start_chunk': 9, 'end_chunk': 10}, {'content': 'MD5: c905a30badb458655009799b1274205c\\nCharacterization: File Hash Watchlist\\nNotes: \"Lightweight backdoor\"\\n     Earliest PE compile time: 20140205T090906Z\\n     Latest PE compile time: 20140205T090906Z', 'start_chunk': 11, 'end_chunk': 12}, {'content': 'MD5: 40adcd738c5bdc5e1cc3ab9a48b3df39\\nCharacterization: File Hash Watchlist\\nNotes: \"Lightweight backdoor\"\\n     Earliest PE compile time: 20140320T152637Z\\n     Latest PE compile time: 20140402T023748Z', 'start_chunk': 13, 'end_chunk': 14}, {'content': 'MD5: 68a26b8eaf2011f16a58e4554ea576a1\\nCharacterization: File Hash Watchlist\\nNotes: \"Lightweight backdoor\"\\n     Earliest PE compile time: 20140321T014949Z\\n     Latest PE compile time: 20140321T014949Z', 'start_chunk': 15, 'end_chunk': 16}, {'content': 'MD5: 74982cd1f3be3d0acfb0e6df22dbcd67\\nCharacterization: File Hash Watchlist\\nNotes: \"Lightweight backdoor\"\\n     Earliest PE compile time: 20140506T020330Z\\n     Latest PE compile time: 20140506T020330Z', 'start_chunk': 17, 'end_chunk': 18}]}\n",
      "Error occurred: The number of references exceeds 5.\n",
      "Trying Query 24\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What specific details are known about the hosting provider and the build strings of the BITTERBUG malware?', 'references': [{'content': 'The threat actors utilized a hosting provider that is a Pakistani-based company with subleased VPS space within the U.S. for command and control (C2).', 'start_chunk': 8, 'end_chunk': 9}, {'content': 'The customized malware (BITTERBUG) used by these threat actors has only been observed hosted on and communicating with two IP addresses operated by a Pakistan-based hosting provider.', 'start_chunk': 9, 'end_chunk': 10}, {'content': 'Early variants of the BITTERBUG malware had build paths containing the strings Tranchulas and Umair Aziz.', 'start_chunk': 11, 'end_chunk': 12}, {'content': 'Tranchulas is the name of a Pakistani security firm; Umair Aziz is the name of a Tranchulas employee.', 'start_chunk': 12, 'end_chunk': 13}]}\n",
      "Trying Query 25\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What is the circumstantial evidence supporting a link to ISIS in the attack on RSS in November 2014?', 'references': [{'content': 'After considering each possibility, we find strong but inconclusive circumstantial evidence to support a link to ISIS.', 'start_chunk': 4, 'end_chunk': 5}, {'content': 'However, we are unable to connect this attack directly to ISIS, Mr. Hussain, or other ISIS supporters.', 'start_chunk': 6, 'end_chunk': 6}, {'content': 'If indeed ISIS or its supporters are responsible, it seems reasonable that such an offensive capability may still be in development.', 'start_chunk': 7, 'end_chunk': 7}]}\n",
      "Trying Query 26\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What is the distribution of ad libraries in Google Play apps?', 'references': [{'content': 'Seventy-one% of the apps contain at least one ad library, 35% have at least two ad libraries, and 22.25% include at least three ad libraries.', 'start_chunk': 19, 'end_chunk': 20}]}\n",
      "Trying Query 27\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What evidence links cpyy to the Chinese military?', 'references': [{'content': 'Several pieces of evidence indicate that cpyy probably has connections to, or is part of, the Chinese military specifically the PLA Army. In addition to his declaration on his personal blog that he works for the military/police, and contacts with actors such as Linxder that have been previously associated with hacking units within the PLA, cpyy', 'start_chunk': 32, 'end_chunk': 34}, {'content': 's Picasa site contains several photographs that hint at military connections. First, a monochrome picture from the college album posted in February 2007 shows several uniformed individuals:', 'start_chunk': 35, 'end_chunk': 40}]}\n",
      "Trying Query 28\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What methods do attackers use during the reconnaissance phase of APT attacks?', 'references': [{'content': 'This phase mostly relies on open sources from the Internet: social networks, press releases, white papers, corporate websites, search engines, but also on some active tools like vulnerability scanners etc.', 'start_chunk': 40, 'end_chunk': 41}, {'content': 'The reconnaissance phase commences when an attacker selects a new target and involves the acquisition of information about that target. There is very little information available about this phase, and there is little data about it. The only way to collect information about this phase would be to already monitor all attackers actions at this step, which is hardly feasible. The longer the attackers spend time in attempting to understand their target and its online presence, the easier it will be to find efficient ways to penetrate that companies systems. This reconnaissance phase is both about finding information to break into the targeted network successfully and about searching for data which could help to accelerate sensitive information isolation (like the name of a key employee for example).', 'start_chunk': 28, 'end_chunk': 36}]}\n",
      "Trying Query 29\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 29\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What APIs are used for clipboard operations in Android?', 'references': [{'content': 'ClipboardManager.getText()', 'start_chunk': 9, 'end_chunk': 9}, {'content': 'ClipboardManager.hasPrimaryClip()', 'start_chunk': 10, 'end_chunk': 10}, {'content': 'ClipboardManager.setText()', 'start_chunk': 11, 'end_chunk': 11}, {'content': 'ClipboardManager.setPrimaryClip()', 'start_chunk': 11, 'end_chunk': 11}, {'content': 'ClipboardManager.hasText()', 'start_chunk': 12, 'end_chunk': 12}, {'content': 'ClipboardManager.addPrimaryClipChangedListener()', 'start_chunk': 13, 'end_chunk': 13}, {'content': 'ClipboardManager.getPrimaryClip()', 'start_chunk': 14, 'end_chunk': 14}]}\n",
      "Error occurred: The number of references exceeds 5.\n",
      "Trying Query 29\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: unterminated string literal (detected at line 13) (<unknown>, line 13)\n",
      "Trying Query 29\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: unterminated string literal (detected at line 3) (<unknown>, line 3)\n",
      "Trying Query 29\n",
      "{'oath': 'I will not use the word \"and\" in the question unless it is part of a proper noun. I will also make sure the question is concise.', 'question': 'How many malware families do Avstore.com.tw and skypetm.com.tw have in common?', 'references': [{'content': 'Avstore.com.tw and skypetm.com.tw have 4 malware families in common, communicating to subdomains of both domains:', 'start_chunk': 22, 'end_chunk': 23}]}\n",
      "Trying Query 30\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 30\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'In which sections are the TLP classification and contact information provided?', 'references': [{'content': 'TLP: Green For any inquiries, please contact intelreports@kaspersky.com', 'start_chunk': 14, 'end_chunk': 14}, {'content': 'TLP: Green For any inquiries, please contact intelreports@kaspersky.com', 'start_chunk': 28, 'end_chunk': 28}, {'content': 'intelreports@kaspersky.com', 'start_chunk': 15, 'end_chunk': 15}]}\n",
      "Trying Query 31\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': \"What OIDs are supported by the Gen 1 and Gen 2 drivers' interfaces?\", 'references': [{'content': 's interface supports the following OIDs: OID 0x12C828 No-op 0x12C82C Retrieves bytes from the recv queue. 0x12C830 Add bytes to the xmit queue. 0x12C838 Set key value (the trigger value) 0x12C840 Change mode for current processs channel to 2 0x12C844 Activates channel 0x12C848 Shuts down a channel by flushing all queued packets/data to the network with ACK|FIN set in the flags 0x12C84C Returns the current mode for a given channel 0x12C850 Get the Drivers version', 'start_chunk': 0, 'end_chunk': 6}, {'content': 'The Driver expose an IOCTL interface that supports the following OIDs: OID', 'start_chunk': 40, 'end_chunk': 41}]}\n",
      "Trying Query 32\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 32\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What entities did Unit 121 reportedly breach in July 2006, and what action coincided with this breach?', 'references': [{'content': \"In July 2006, North Korea's Unit 121 reportedly breached South Korean and U.S. military entities.308 This attack was concurrent with the regime's test-fire of at least one long-range missile and several medium-range missiles.309\", 'start_chunk': 42, 'end_chunk': 43}]}\n",
      "Trying Query 33\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 33\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What specific incidents indicate APT28 attempts to compromise Eastern European government organizations?', 'references': [{'content': \"In a late 2013 incident, a FireEye device deployed at an Eastern European Ministry of Foreign Affairs detected APT28 malware in the client's network.\", 'start_chunk': 25, 'end_chunk': 28}, {'content': 'More recently, in August 2014 APT28 used a lure (Figure 3) about hostilities surrounding a Malaysia Airlines flight downed in Ukraine in a probable attempt to compromise the Polish government.', 'start_chunk': 31, 'end_chunk': 35}]}\n",
      "Trying Query 34\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What evidence ties the PUTTER PANDA group to PLA Unit 61486?', 'references': [{'content': 'There is strong evidence to tie cpyy, an actor who appears to have been involved in historical PUTTER PANDA operations, to the PLA army and a location in Shanghai that is operated by the 12th Bureau, 3rd GSD of the PLA (Unit 61486).', 'start_chunk': 14, 'end_chunk': 16}, {'content': 'Another actor tied to this activity, httpchen, has declared publicly that he was attending the School of Information Security Engineering at SJTU. This university has previously been posited as a recruiting ground for the PLA to find personnel for its cyber intelligence gathering units, and there is circumstantial evidence linked cpyy to other actors based at SJTU.', 'start_chunk': 17, 'end_chunk': 19}, {'content': 'Given the evidence outlined above, CrowdStrike attributes the PUTTER PANDA group to PLA Unit 61486 within Shanghai, China with high confidence.', 'start_chunk': 21, 'end_chunk': 22}]}\n",
      "Trying Query 35\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 35\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What does the network reconnaissance tool in the Snake rootkit retrieve, and where is this data stored?', 'references': [{'content': 'One of the Snake components that could have been downloaded from a remote C&C server, was identified as a network reconnaissance tool. When run as a command line tool, with its logic defined with the command line switches, this tool enumerates other network hosts and detects what Windows RPC services are enabled at the endpoints. It carries a list of interface identifiers associated with the named pipes. It then uses these identifiers to write a message to and read a message from the associated named pipes. By knowing what RPC services are running, it can successfully fingerprint all network hosts by mimicking the Metasploit s logic of OS fingerprinting via SMB.', 'start_chunk': 12, 'end_chunk': 19}, {'content': 'The data it retrieves is encrypted and saved into a configuration file %system%\\x0btmon.bin. This file is then further encrypted with an NTL-based (Number Theory Library) algorithm and is uploaded by the usermode-centric Snake rootkit to the C&C server, along with other configuration files, such as mtmon.sdb, mtmon32.sdb, gstatsnd.bin, gstat.bin, gstat32.bin, and other log files found in the %windows%\\\\$NtUninstallQ[random]$ directory.', 'start_chunk': 21, 'end_chunk': 24}]}\n",
      "Trying Query 36\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun.\", 'question': 'What email addresses are associated with the technical contact for uriminzokkiri.com?', 'references': [{'content': 'Email : hyk1979@hotmail.com', 'start_chunk': 13, 'end_chunk': 13}, {'content': 'Email : hyk1979@hotmail.com', 'start_chunk': 17, 'end_chunk': 17}]}\n",
      "Trying Query 37\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What servers did Operation Cleaver use for exfiltration?', 'references': [{'content': 'Anonymous FTP Servers Cleaver Operations observed in 2013 mainly utilized FTP servers with anonymous access enabled in order to pilfer large quantities of information.', 'start_chunk': 18, 'end_chunk': 19}, {'content': 'The following IP addresses hosted FTP servers that were used in the infection of targets or in the exfiltration of information.', 'start_chunk': 24, 'end_chunk': 25}, {'content': '108.175.152.230 Santa Rosa, CA, USA', 'start_chunk': 25, 'end_chunk': 25}, {'content': '108.175.153.158 Santa Rosa, CA, USA', 'start_chunk': 26, 'end_chunk': 26}, {'content': '184.82.181.48 Pilot Mountain, North Carolina, USA', 'start_chunk': 26, 'end_chunk': 27}, {'content': '203.150.224.249 Thailand', 'start_chunk': 27, 'end_chunk': 27}, {'content': '64.120.208.74 Pilot Mountain, North Carolina, USA', 'start_chunk': 27, 'end_chunk': 28}, {'content': '64.120.208.75 Pilot Mountain, North Carolina, USA', 'start_chunk': 28, 'end_chunk': 28}, {'content': '64.120.208.76 Pilot Mountain, North Carolina, USA', 'start_chunk': 28, 'end_chunk': 29}, {'content': '64.120.208.78 Pilot Mountain, North Carolina, USA', 'start_chunk': 29, 'end_chunk': 29}, {'content': '66.96.252.198 Pilot Mountain, North Carolina, USA', 'start_chunk': 30, 'end_chunk': 30}]}\n",
      "Error occurred: The number of references exceeds 5.\n",
      "Trying Query 37\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What malware tools are detected as used by the Darkhotel APT?', 'references': [{'content': 'Darkhotel tools are detected as Tapaoux Pioneer Karba, and Nemim, among other names.', 'start_chunk': 26, 'end_chunk': 26}]}\n",
      "Trying Query 38\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'Where is NUST mentioned in the text?', 'references': [{'content': 'National s TUniversity', 'start_chunk': 22, 'end_chunk': 22}, {'content': 'NUST).   SciencesLinkedIn', 'start_chunk': 30, 'end_chunk': 30}, {'content': '45 (NUST).46', 'start_chunk': 38, 'end_chunk': 38}]}\n",
      "Trying Query 39\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What are the compile times of the executable files mentioned in the text?', 'references': [{'content': 'PE Compile Time: 2014-11-13 02:05:35', 'start_chunk': 7, 'end_chunk': 8}, {'content': 'PE Compile Time: 2009-08-21 06:05:32', 'start_chunk': 10, 'end_chunk': 11}, {'content': 'PE Compile Time: 2009-08-21 06:05:35', 'start_chunk': 14, 'end_chunk': 15}, {'content': 'PE Compile Time: 2014-07-07 08:01:09', 'start_chunk': 18, 'end_chunk': 19}]}\n",
      "Trying Query 40\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 40\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'Which subdomains of avstore.com.tw are associated with malware activity according to the text?', 'references': [{'content': 'ey.avstore.com.tw', 'start_chunk': 30, 'end_chunk': 30}, {'content': 'mac.avstore.com.tw', 'start_chunk': 31, 'end_chunk': 31}, {'content': 'sop.avstore.com.tw', 'start_chunk': 32, 'end_chunk': 32}, {'content': 'chanxe.avstore.com.tw', 'start_chunk': 35, 'end_chunk': 35}, {'content': 'jackyandy.avstore.com.tw', 'start_chunk': 37, 'end_chunk': 38}]}\n",
      "Trying Query 41\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 41\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'Who is the sender of the email referenced in the text, and what is the email’s subject?', 'references': [{'content': 'kevin.bohn33@hotmail.com, Contagio March', 'start_chunk': 1, 'end_chunk': 1}, {'content': 'Mar 27 CVE 2010 0806 IE 0 day Dozens missing after ship sinks near North Korea from', 'start_chunk': 0, 'end_chunk': 0}]}\n",
      "Trying Query 42\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'Which sectors do the companies targeted by Pitty Tiger operate in?', 'references': [{'content': '1 company from the defense industry;', 'start_chunk': 38, 'end_chunk': 38}, {'content': '1 company from the energy industry;', 'start_chunk': 39, 'end_chunk': 39}, {'content': '1 company from the telecommunications industry;', 'start_chunk': 39, 'end_chunk': 40}, {'content': '1 company specialized in web development.', 'start_chunk': 40, 'end_chunk': 40}]}\n",
      "Trying Query 43\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 43\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What compile times are associated with BITTERBUG in the debug paths?', 'references': [{'content': 'Additional BITTERBUG', 'start_chunk': 0, 'end_chunk': 0}, {'content': 'Additional variants were compiled in June and July 2013.', 'start_chunk': 3, 'end_chunk': 3}, {'content': 'in', 'start_chunk': 19, 'end_chunk': 19}]}\n",
      "Trying Query 44\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What happened in 2013 regarding the Austrian and German power grid?', 'references': [{'content': 'In 2013 part of the Austrian and German power grid nearly broke down after a control command was accidentally misdirected. It is believed that a status request command packet, which was broadcast from a German gas company as a test for their newly installed network branch, found its way into the systems of the Austrian energy power control and monitoring network. Once there, the message generated thousands of reply messages, which generated even more data packages, which in turn flooded the control network. To stop this self-inflicted DDoS attack, part of the monitoring and control network had to be isolated and disconnected. Fortunately the situation was resolved without any power outages.', 'start_chunk': 32, 'end_chunk': 39}]}\n",
      "Trying Query 45\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 45\n",
      "{'oath': 'I will not use the word \"and\" in the question unless it is part of a proper noun. I will also make sure the question is concise.', 'question': 'What is represented by the sections labeled \"Samples (MD5)\" and \"Samples (SHA-256)\" in the text?', 'references': [{'content': 'Samples (MD5)', 'start_chunk': 16, 'end_chunk': 16}, {'content': 'Samples (SHA-256)', 'start_chunk': 31, 'end_chunk': 31}]}\n",
      "Trying Query 46\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What specific MITM attacks are discussed in the text?', 'references': [{'content': \"ined MITM attacks22,23. with the launcher modification attack introduced earlier, the attackers can redirect other app icons (e.g., bank or email app icons) to the phishing app and steal the user's login credentials.\", 'start_chunk': 0, 'end_chunk': 3}]}\n",
      "Trying Query 47\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 47\n",
      "{'oath': 'I will not use the word \"and\" in the question unless it is part of a proper noun. I will also make sure the question is concise.', 'question': \"What does the leaked report mention regarding Pakistan's inability to locate Osama Bin Laden?\", 'references': [{'content': \"leaked report which contained a decoy named lure document related to Pakistan's alleged inability to locate Osama Bin Laden.\", 'start_chunk': 26, 'end_chunk': 28}]}\n",
      "Trying Query 48\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What is the validity period of the certificate?', 'references': [{'content': 'Not Before: Nov 12 16:59:48 2008 GMT\\n        Not After : Nov 12 16:59:48 2011 GMT', 'start_chunk': 33, 'end_chunk': 33}]}\n",
      "Trying Query 49\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 49\n",
      "Error occurred: Failed to parse the remaining text as a dictionary: invalid syntax (<unknown>, line 1)\n",
      "Trying Query 49\n",
      "{'oath': \"I will not use the word 'and' in the question unless it is part of a proper noun. I will also make sure the question is concise.\", 'question': 'What are the names of the log files created during malware execution, and what key differences exist in their structure between versions older than 3.26 and version 3.26?', 'references': [{'content': 'Two log files are created during the malware execution: mskfp32.ocx and msvcrtd.tlb. If the malware version is older than 3.26, the xored key is the same as the dropper key. Concerning the version 3.26, the malware uses a new non-ASCII key.', 'start_chunk': 1, 'end_chunk': 3}, {'content': 'Here is an example of decoded log file for the version 3.26: [...] The command and control server information is stored in the registry, not in an XML, and encoded:', 'start_chunk': 3, 'end_chunk': 4}]}\n"
     ]
    }
   ],
   "source": [
    "# Specify the corpora paths, you can have multiple but we'll just use our one file\n",
    "corpora_paths = [\n",
    "    'chunking_evaluation/cybersecurity/cyberclean.txt',\n",
    "    'chunking_evaluation/cybersecurity/reportsclean.txt'\n",
    "]\n",
    "\n",
    "csv_path = 'chunking_evaluation/cybersecurity_results_DeepSeek-R1-Distill-Llama-70B.csv'\n",
    "\n",
    "# Initialize the evaluation\n",
    "synthetic_pipeline = SyntheticEvaluation(corpora_paths, csv_path)\n",
    "synthetic_pipeline.generate_queries_and_excerpts(approximate_excerpts=True,\n",
    "                                         num_rounds=1,\n",
    "                                         queries_per_corpus=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5fce868-6cbc-4b48-8940-820e94c052ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>references</th>\n",
       "      <th>corpus_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What supplementary NSA guidance is available f...</td>\n",
       "      <td>[{\"content\": \"(CI/CD) Environments\\nFurther gu...</td>\n",
       "      <td>chunking_evaluation/cybersecurity/cyberclean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the key steps to mitigate the modific...</td>\n",
       "      <td>[{\"content\": \"to hide malicious code,\\nreduce ...</td>\n",
       "      <td>chunking_evaluation/cybersecurity/cyberclean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What Execution techniques does an MCA employ t...</td>\n",
       "      <td>[{\"content\": \"consists of techniques that resu...</td>\n",
       "      <td>chunking_evaluation/cybersecurity/cyberclean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do you create a text hexadecimal hash for ...</td>\n",
       "      <td>[{\"content\": \"files can be signed to become AU...</td>\n",
       "      <td>chunking_evaluation/cybersecurity/cyberclean.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What key tasks are outlined in the FPGA config...</td>\n",
       "      <td>[{\"content\": \"........................ 54\\nVer...</td>\n",
       "      <td>chunking_evaluation/cybersecurity/cyberclean.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What supplementary NSA guidance is available f...   \n",
       "1  What are the key steps to mitigate the modific...   \n",
       "2  What Execution techniques does an MCA employ t...   \n",
       "3  How do you create a text hexadecimal hash for ...   \n",
       "4  What key tasks are outlined in the FPGA config...   \n",
       "\n",
       "                                          references  \\\n",
       "0  [{\"content\": \"(CI/CD) Environments\\nFurther gu...   \n",
       "1  [{\"content\": \"to hide malicious code,\\nreduce ...   \n",
       "2  [{\"content\": \"consists of techniques that resu...   \n",
       "3  [{\"content\": \"files can be signed to become AU...   \n",
       "4  [{\"content\": \"........................ 54\\nVer...   \n",
       "\n",
       "                                          corpus_id  \n",
       "0  chunking_evaluation/cybersecurity/cyberclean.txt  \n",
       "1  chunking_evaluation/cybersecurity/cyberclean.txt  \n",
       "2  chunking_evaluation/cybersecurity/cyberclean.txt  \n",
       "3  chunking_evaluation/cybersecurity/cyberclean.txt  \n",
       "4  chunking_evaluation/cybersecurity/cyberclean.txt  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_df = pd.read_csv(\"chunking_evaluation/cybersecurity_results_DeepSeek-R1-Distill-Llama-70B.csv\")\n",
    "synthetic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "807316e2-10eb-4238-8074-d122d553a77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunking_evaluation import GeneralEvaluation, SyntheticEvaluation, BaseChunker\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "class SentenceChunker(BaseChunker):\n",
    "    def __init__(self, sentences_per_chunk: int = 3):\n",
    "        # Initialize the chunker with the number of sentences per chunk\n",
    "        self.sentences_per_chunk = sentences_per_chunk\n",
    "\n",
    "    def split_text(self, text: str) -> List[str]:\n",
    "        # Handle the case where the input text is empty\n",
    "        if not text:\n",
    "            return []\n",
    "\n",
    "        # Split the input text into sentences using regular expression\n",
    "        # Regex looks for white space following . ! or ? and makes a split\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "        chunks = []\n",
    "\n",
    "        # Group sentences into chunks based on the specified number\n",
    "        for i in range(0, len(sentences), self.sentences_per_chunk):\n",
    "            # Combine sentences into a single chunk\n",
    "            chunk = ' '.join(sentences[i:i + self.sentences_per_chunk])\n",
    "            chunks.append(chunk)\n",
    "        \n",
    "        # Return the list of chunks\n",
    "        return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10d10d3c-8c88-4375-87d5-98d4f4bf8c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function\n",
    "def print_metrics(results):\n",
    "    \n",
    "    # Grab Summary Metrics    \n",
    "    metrics = {\n",
    "        'Recall': (results['recall_mean'], results['recall_std']),\n",
    "        'Precision': (results['precision_mean'], results['precision_std']),\n",
    "        'Precision Ω': (results['precision_omega_mean'], results['precision_omega_std']),\n",
    "        'IoU': (results['iou_mean'], results['iou_std'])\n",
    "    }\n",
    "    \n",
    "    # Print each metric with mean ± std\n",
    "    for metric, (mean, std) in metrics.items():\n",
    "        print(f\"{metric}: {mean:.4f} ± {std:.4f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebbb75ec-bbb8-46ef-81a5-22755020edab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iou_mean</th>\n",
       "      <th>iou_std</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>precision_omega_mean</th>\n",
       "      <th>precision_omega_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>chunker</th>\n",
       "      <th>chunk_size</th>\n",
       "      <th>embedding_function</th>\n",
       "      <th>config</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042323</td>\n",
       "      <td>0.044814</td>\n",
       "      <td>0.491729</td>\n",
       "      <td>0.409595</td>\n",
       "      <td>0.195943</td>\n",
       "      <td>0.122531</td>\n",
       "      <td>0.044452</td>\n",
       "      <td>0.046763</td>\n",
       "      <td>SentenceChunker</td>\n",
       "      <td>5</td>\n",
       "      <td>OpenAIEmbeddingFunction</td>\n",
       "      <td>SentenceChunker_5_OpenAIEmbeddingFunction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030474</td>\n",
       "      <td>0.028673</td>\n",
       "      <td>0.615520</td>\n",
       "      <td>0.404676</td>\n",
       "      <td>0.124257</td>\n",
       "      <td>0.082780</td>\n",
       "      <td>0.031091</td>\n",
       "      <td>0.029549</td>\n",
       "      <td>SentenceChunker</td>\n",
       "      <td>10</td>\n",
       "      <td>OpenAIEmbeddingFunction</td>\n",
       "      <td>SentenceChunker_10_OpenAIEmbeddingFunction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021067</td>\n",
       "      <td>0.021181</td>\n",
       "      <td>0.593829</td>\n",
       "      <td>0.420130</td>\n",
       "      <td>0.097180</td>\n",
       "      <td>0.069179</td>\n",
       "      <td>0.021297</td>\n",
       "      <td>0.021525</td>\n",
       "      <td>SentenceChunker</td>\n",
       "      <td>15</td>\n",
       "      <td>OpenAIEmbeddingFunction</td>\n",
       "      <td>SentenceChunker_15_OpenAIEmbeddingFunction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.019268</td>\n",
       "      <td>0.019050</td>\n",
       "      <td>0.651514</td>\n",
       "      <td>0.410001</td>\n",
       "      <td>0.082155</td>\n",
       "      <td>0.056704</td>\n",
       "      <td>0.019386</td>\n",
       "      <td>0.019183</td>\n",
       "      <td>SentenceChunker</td>\n",
       "      <td>20</td>\n",
       "      <td>OpenAIEmbeddingFunction</td>\n",
       "      <td>SentenceChunker_20_OpenAIEmbeddingFunction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iou_mean   iou_std  recall_mean  recall_std  precision_omega_mean  \\\n",
       "0  0.042323  0.044814     0.491729    0.409595              0.195943   \n",
       "1  0.030474  0.028673     0.615520    0.404676              0.124257   \n",
       "2  0.021067  0.021181     0.593829    0.420130              0.097180   \n",
       "3  0.019268  0.019050     0.651514    0.410001              0.082155   \n",
       "\n",
       "   precision_omega_std  precision_mean  precision_std          chunker  \\\n",
       "0             0.122531        0.044452       0.046763  SentenceChunker   \n",
       "1             0.082780        0.031091       0.029549  SentenceChunker   \n",
       "2             0.069179        0.021297       0.021525  SentenceChunker   \n",
       "3             0.056704        0.019386       0.019183  SentenceChunker   \n",
       "\n",
       "   chunk_size       embedding_function  \\\n",
       "0           5  OpenAIEmbeddingFunction   \n",
       "1          10  OpenAIEmbeddingFunction   \n",
       "2          15  OpenAIEmbeddingFunction   \n",
       "3          20  OpenAIEmbeddingFunction   \n",
       "\n",
       "                                       config  \n",
       "0   SentenceChunker_5_OpenAIEmbeddingFunction  \n",
       "1  SentenceChunker_10_OpenAIEmbeddingFunction  \n",
       "2  SentenceChunker_15_OpenAIEmbeddingFunction  \n",
       "3  SentenceChunker_20_OpenAIEmbeddingFunction  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining our Configurations\n",
    "chunkers = [\n",
    "    SentenceChunker(sentences_per_chunk = 5),\n",
    "    SentenceChunker(sentences_per_chunk = 10),\n",
    "    SentenceChunker(sentences_per_chunk = 15),\n",
    "    SentenceChunker(sentences_per_chunk = 20),\n",
    "]\n",
    "\n",
    "# Defining our Embedding Functions\n",
    "embedders = [\n",
    "    embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_base=\"http://127.0.0.1:1234/v1\",\n",
    "    api_key=\"lm-studio\",\n",
    "    model_name=\"text-embedding-bge-m3\"\n",
    ")\n",
    "\n",
    "]\n",
    "\n",
    "# Initialize Results Storage\n",
    "synth_results = []\n",
    "\n",
    "# Helper Function\n",
    "def get_config_name(chunker, ef):\n",
    "    chunk_size = chunker.sentences_per_chunk if hasattr(chunker, 'sentences_per_chunk') else 0\n",
    "    ef_name = ef.model_name if hasattr(ef, 'model_name') else ef.__class__.__name__\n",
    "    return f\"{chunker.__class__.__name__}_{chunk_size}_{ef_name}\"\n",
    "\n",
    "# Progress tracking\n",
    "total_combinations = len(chunkers) * len(embedders)\n",
    "current_combination = 0\n",
    "\n",
    "# Run evaluation sweep\n",
    "for chunker in chunkers:\n",
    "    for ef in embedders:\n",
    "        current_combination += 1\n",
    "        try:\n",
    "            print(f\"Evaluating combination {current_combination}/{total_combinations}:\")\n",
    "            print(f\"  Chunker: {chunker.__class__.__name__} (size: {chunker.sentences_per_chunk})\")\n",
    "            print(f\"  Embedding: {ef.model_name if hasattr(ef, 'model_name') else ef.__class__.__name__}\")\n",
    "            \n",
    "            # Run evaluation\n",
    "            result = synthetic_pipeline.run(chunker, ef, retrieve=5)\n",
    "            \n",
    "            # Clean up and store results\n",
    "            if 'corpora_scores' in result:\n",
    "                del result['corpora_scores']\n",
    "            \n",
    "            # Add configuration identifiers\n",
    "            result['chunker'] = chunker.__class__.__name__\n",
    "            result['chunk_size'] = chunker.sentences_per_chunk\n",
    "            result['embedding_function'] = ef.model_name if hasattr(ef, 'model_name') else ef.__class__.__name__\n",
    "            result['config'] = get_config_name(chunker, ef)\n",
    "            \n",
    "            synth_results.append(result)\n",
    "            clear_output(wait=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Error Handling Just in Case\n",
    "            print(f\"Error in combination {current_combination}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "# Create final DataFrame and display\n",
    "synth_df = pd.DataFrame(synth_results)\n",
    "print(\"\\nFinal Results:\")\n",
    "display(synth_df)\n",
    "file_name = \"cybersecurity-DeepSeek-R1-Distill-Llama-70B-BGE-M3.xlsx\"\n",
    "synth_df.to_excel(file_name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0816f387-142f-40d5-ad2a-b49061bdd75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iou_mean</th>\n",
       "      <th>iou_std</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>precision_omega_mean</th>\n",
       "      <th>precision_omega_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>chunker</th>\n",
       "      <th>chunk_size</th>\n",
       "      <th>embedding_function</th>\n",
       "      <th>config</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042222</td>\n",
       "      <td>0.048184</td>\n",
       "      <td>0.382884</td>\n",
       "      <td>0.392884</td>\n",
       "      <td>0.195943</td>\n",
       "      <td>0.122531</td>\n",
       "      <td>0.044580</td>\n",
       "      <td>0.049918</td>\n",
       "      <td>SentenceChunker</td>\n",
       "      <td>5</td>\n",
       "      <td>OpenAIEmbeddingFunction</td>\n",
       "      <td>SentenceChunker_5_OpenAIEmbeddingFunction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.022414</td>\n",
       "      <td>0.030424</td>\n",
       "      <td>0.358783</td>\n",
       "      <td>0.416037</td>\n",
       "      <td>0.124257</td>\n",
       "      <td>0.082780</td>\n",
       "      <td>0.022930</td>\n",
       "      <td>0.030939</td>\n",
       "      <td>SentenceChunker</td>\n",
       "      <td>10</td>\n",
       "      <td>OpenAIEmbeddingFunction</td>\n",
       "      <td>SentenceChunker_10_OpenAIEmbeddingFunction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015498</td>\n",
       "      <td>0.023358</td>\n",
       "      <td>0.338482</td>\n",
       "      <td>0.421248</td>\n",
       "      <td>0.097180</td>\n",
       "      <td>0.069179</td>\n",
       "      <td>0.015734</td>\n",
       "      <td>0.023587</td>\n",
       "      <td>SentenceChunker</td>\n",
       "      <td>15</td>\n",
       "      <td>OpenAIEmbeddingFunction</td>\n",
       "      <td>SentenceChunker_15_OpenAIEmbeddingFunction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010470</td>\n",
       "      <td>0.016681</td>\n",
       "      <td>0.279655</td>\n",
       "      <td>0.388131</td>\n",
       "      <td>0.082155</td>\n",
       "      <td>0.056704</td>\n",
       "      <td>0.010635</td>\n",
       "      <td>0.016850</td>\n",
       "      <td>SentenceChunker</td>\n",
       "      <td>20</td>\n",
       "      <td>OpenAIEmbeddingFunction</td>\n",
       "      <td>SentenceChunker_20_OpenAIEmbeddingFunction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iou_mean   iou_std  recall_mean  recall_std  precision_omega_mean  \\\n",
       "0  0.042222  0.048184     0.382884    0.392884              0.195943   \n",
       "1  0.022414  0.030424     0.358783    0.416037              0.124257   \n",
       "2  0.015498  0.023358     0.338482    0.421248              0.097180   \n",
       "3  0.010470  0.016681     0.279655    0.388131              0.082155   \n",
       "\n",
       "   precision_omega_std  precision_mean  precision_std          chunker  \\\n",
       "0             0.122531        0.044580       0.049918  SentenceChunker   \n",
       "1             0.082780        0.022930       0.030939  SentenceChunker   \n",
       "2             0.069179        0.015734       0.023587  SentenceChunker   \n",
       "3             0.056704        0.010635       0.016850  SentenceChunker   \n",
       "\n",
       "   chunk_size       embedding_function  \\\n",
       "0           5  OpenAIEmbeddingFunction   \n",
       "1          10  OpenAIEmbeddingFunction   \n",
       "2          15  OpenAIEmbeddingFunction   \n",
       "3          20  OpenAIEmbeddingFunction   \n",
       "\n",
       "                                       config  \n",
       "0   SentenceChunker_5_OpenAIEmbeddingFunction  \n",
       "1  SentenceChunker_10_OpenAIEmbeddingFunction  \n",
       "2  SentenceChunker_15_OpenAIEmbeddingFunction  \n",
       "3  SentenceChunker_20_OpenAIEmbeddingFunction  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining our Configurations\n",
    "chunkers = [\n",
    "    SentenceChunker(sentences_per_chunk = 5),\n",
    "    SentenceChunker(sentences_per_chunk = 10),\n",
    "    SentenceChunker(sentences_per_chunk = 15),\n",
    "    SentenceChunker(sentences_per_chunk = 20),\n",
    "]\n",
    "\n",
    "# Defining our Embedding Functions\n",
    "embedders = [\n",
    "    embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_base=\"http://localhost:11434/v1\",\n",
    "    api_key=\"lm-studio\",\n",
    "    model_name=\"nomic-embed-text\"\n",
    ")\n",
    "\n",
    "]\n",
    "\n",
    "# Initialize Results Storage\n",
    "synth_results = []\n",
    "\n",
    "# Helper Function\n",
    "def get_config_name(chunker, ef):\n",
    "    chunk_size = chunker.sentences_per_chunk if hasattr(chunker, 'sentences_per_chunk') else 0\n",
    "    ef_name = ef.model_name if hasattr(ef, 'model_name') else ef.__class__.__name__\n",
    "    return f\"{chunker.__class__.__name__}_{chunk_size}_{ef_name}\"\n",
    "\n",
    "# Progress tracking\n",
    "total_combinations = len(chunkers) * len(embedders)\n",
    "current_combination = 0\n",
    "\n",
    "# Run evaluation sweep\n",
    "for chunker in chunkers:\n",
    "    for ef in embedders:\n",
    "        current_combination += 1\n",
    "        try:\n",
    "            print(f\"Evaluating combination {current_combination}/{total_combinations}:\")\n",
    "            print(f\"  Chunker: {chunker.__class__.__name__} (size: {chunker.sentences_per_chunk})\")\n",
    "            print(f\"  Embedding: {ef.model_name if hasattr(ef, 'model_name') else ef.__class__.__name__}\")\n",
    "            \n",
    "            # Run evaluation\n",
    "            result = synthetic_pipeline.run(chunker, ef, retrieve=5)\n",
    "            \n",
    "            # Clean up and store results\n",
    "            if 'corpora_scores' in result:\n",
    "                del result['corpora_scores']\n",
    "            \n",
    "            # Add configuration identifiers\n",
    "            result['chunker'] = chunker.__class__.__name__\n",
    "            result['chunk_size'] = chunker.sentences_per_chunk\n",
    "            result['embedding_function'] = ef.model_name if hasattr(ef, 'model_name') else ef.__class__.__name__\n",
    "            result['config'] = get_config_name(chunker, ef)\n",
    "            \n",
    "            synth_results.append(result)\n",
    "            clear_output(wait=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Error Handling Just in Case\n",
    "            print(f\"Error in combination {current_combination}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "# Create final DataFrame and display\n",
    "synth_df = pd.DataFrame(synth_results)\n",
    "print(\"\\nFinal Results:\")\n",
    "display(synth_df)\n",
    "file_name = \"cybersecurity-DeepSeek-R1-Distill-Llama-70B-Nomic.xlsx\"\n",
    "synth_df.to_excel(file_name,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2025",
   "language": "python",
   "name": "papers_2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
